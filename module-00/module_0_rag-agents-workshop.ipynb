{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "wFM-GCDPTC_f",
      "metadata": {
        "id": "wFM-GCDPTC_f"
      },
      "source": [
        "# From RAG to Agents: Building Smart AI Assistants\n",
        "\n",
        "Videos:\n",
        "\n",
        "* Part 1: https://www.youtube.com/watch?v=GH3lrOsU3AU\n",
        "* Part 2: https://www.youtube.com/watch?v=yS_hwnJusDk\n",
        "\n",
        "In this [workshop](https://github.com/alexeygrigorev/rag-agents-workshop) we\n",
        "\n",
        "* Build a RAG application on the FAQ database\n",
        "* Make it agentic\n",
        "* Learn about agentic search\n",
        "* Give tools to our agents\n",
        "* Use PydanticAI to make it easier\n",
        "\n",
        "You can learn more about agents in the upcoming [AI Bootcamp course](https://maven.com/alexey-grigorev/from-rag-to-agents). Use code \"DTC\" to get $99 off.\n",
        "\n",
        "Based on the code of this workshop, we developed a library [\"Toy AI Kit\"](https://github.com/alexeygrigorev/toyaikit). This library simplifies the interaction with OpenAI API when developing agents and helps better understand how other agent libraries are implemented.\n",
        "\n",
        "For this workshop, we will use the following FAQ documents from our free courses:\n",
        "\n",
        "* Machine Learning Zoomcamp\n",
        "* Data Engineering Zoomcamp\n",
        "* MLOps Zoomcamp"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5E-b8OaLTY44",
      "metadata": {
        "id": "5E-b8OaLTY44"
      },
      "source": [
        "## Environment\n",
        "* For this workshop, all you need is Python with Jupyter.\n",
        "* I use GitHub Codespaces to run it (see [here](https://www.loom.com/share/80c17fbadc9442d3a4829af56514a194)) but you can use whatever environment you like.\n",
        "* Also, you need an OpenAI account (or an alternative provider).\n",
        "\n",
        "### Setting up Github Codespaces\n",
        "Github Codespaces is the recommended environment for this workshop. But you can use any other environment with Jupyter Notebook, including your laptop and Google Colab.\n",
        "\n",
        "* Create a repository on GitHub, initialize it with README.md\n",
        "* Add the OpenAI key:\n",
        "  * Go to Settings -> Secrets and Variables (under Security) -> Codespaces\n",
        "  * Click \"New repository secret\"\n",
        "  * Name: OPENAI_API_KEY, Secret: your key\n",
        "  * Click \"Add secret\"\n",
        "* Create a codespace\n",
        "  * Click \"Code\"\n",
        "  * Select the \"Codespaces\" tab\n",
        "  * \"Create codespaces on main\"\n",
        "\n",
        "### Installing required libraries\n",
        "Next we need to install the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "qostHlTqUHEw",
      "metadata": {
        "id": "qostHlTqUHEw"
      },
      "outputs": [],
      "source": [
        "#%pip install jupyter openai minsearch requests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PAASKnPIs9WJ",
      "metadata": {
        "id": "PAASKnPIs9WJ"
      },
      "source": [
        "# Part 0: Basic RAG\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AUVffHYLtsTe",
      "metadata": {
        "id": "AUVffHYLtsTe"
      },
      "source": [
        "## Minsearch\n",
        "\n",
        "First, we implement a basic search function that will query our FAQ database. This function takes a query string and returns relevant documents. We will use minsearch for that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "14c16169-249c-48fb-b2db-abde63ee0f3f",
      "metadata": {
        "id": "14c16169-249c-48fb-b2db-abde63ee0f3f"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from minsearch import AppendableIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "44ccc1a0-d2be-4783-810f-215dd9c7a866",
      "metadata": {
        "id": "44ccc1a0-d2be-4783-810f-215dd9c7a866"
      },
      "outputs": [],
      "source": [
        "# Download and process the FAQ documents for the RAG system:\n",
        "import requests\n",
        "\n",
        "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
        "docs_response = requests.get(docs_url)\n",
        "# Parses the downloaded JSON into a Python object (a list of courses, each with documents)\n",
        "documents_raw = docs_response.json()\n",
        "\n",
        "documents = []\n",
        "\n",
        "for course in documents_raw:\n",
        "    course_name = course['course'] # Extract the course name for each course\n",
        "\n",
        "    for doc in course['documents']: # Extract each document in the course\n",
        "        doc['course'] = course_name # Add the course name to each document\n",
        "        documents.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "483e5565-8d81-4897-bc3a-50dd1c5b871d",
      "metadata": {
        "id": "483e5565-8d81-4897-bc3a-50dd1c5b871d",
        "outputId": "6c40b78a-af0d-413a-c92a-bd650c6f6395"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<minsearch.append.AppendableIndex at 0x73d2ba9b70d0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creates an index of all FAQ documents so they can be searched efficiently:\n",
        "index = AppendableIndex( # Class from the minsearch library used for fast text search\n",
        "    text_fields=[\"question\", \"text\", \"section\"], # Specifies which fields in each document should be searched as text\n",
        "    keyword_fields=[\"course\"] # Specifies fields that are treated as exact-match keywords\n",
        ")\n",
        "\n",
        "index.fit(documents) # Builds the index from the documents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GLrCNOVauaQB",
      "metadata": {
        "id": "GLrCNOVauaQB"
      },
      "source": [
        "## Search\n",
        "\n",
        "Explanation:\n",
        "\n",
        "* This function is the foundation of our RAG system\n",
        "* It looks up in the FAQ to find relevant information\n",
        "* The result is used to build context for the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fb005100-6417-4e6e-9d36-eb3b55416522",
      "metadata": {
        "id": "fb005100-6417-4e6e-9d36-eb3b55416522"
      },
      "outputs": [],
      "source": [
        "# Search the documents:\n",
        "def search(query):\n",
        "    boost = {'question': 3.0, 'section': 0.5}\n",
        "    # Calls the search method on the FAQ index\n",
        "    results = index.search(\n",
        "        query=query, # The search query provided by the user\n",
        "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
        "        boost_dict=boost,\n",
        "        num_results=5, # Returns the top 5 results\n",
        "        output_ids=True # Returns the IDs of the documents in the results\n",
        "    )\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8aff5ae7-7053-4617-9250-a6ad293bec6f",
      "metadata": {
        "id": "8aff5ae7-7053-4617-9250-a6ad293bec6f",
        "outputId": "5d5e09e0-a8d1-45b2-d1fe-a356f0b3b76d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
            "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n"
          ]
        }
      ],
      "source": [
        "results = search('I just discovered the course. Can I join now?')\n",
        "print(results[0]['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PWUc580-urhL",
      "metadata": {
        "id": "PWUc580-urhL"
      },
      "source": [
        "## Prompt\n",
        "\n",
        "We create a function to format the search results into a structured context that our LLM can use. This code prepares a structured prompt for the LLM, ensuring it answers the user's question using only the relevant FAQ entries found by the search. This is a key step in the RAG workflow, providing the LLM with the necessary context for accurate and grounded responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "45da236b-e7ec-4d16-88d3-527227bcf311",
      "metadata": {
        "id": "45da236b-e7ec-4d16-88d3-527227bcf311"
      },
      "outputs": [],
      "source": [
        "# Defines a string template for the prompt that will be sent to the LLM\n",
        "prompt_template = \"\"\"\n",
        "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
        "Use only the facts from the CONTEXT when answering the QUESTION.\n",
        "\n",
        "<QUESTION>\n",
        "{question}\n",
        "</QUESTION>\n",
        "\n",
        "<CONTEXT>\n",
        "{context}\n",
        "</CONTEXT>\n",
        "\"\"\".strip()\n",
        "# Defines a function to build the actual prompt for the LLM\n",
        "def build_prompt(query, search_results):\n",
        "    context = \"\" # Initializes an empty string to accumulate context from search results\n",
        "    # Appends section, question, and answer to the context string in a readable format\n",
        "    for doc in search_results:\n",
        "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
        "    # Fills in the template with the actual question and the constructed context\n",
        "    prompt = prompt_template.format(question=query, context=context).strip()\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "h4jZaOwYtQTH",
      "metadata": {
        "id": "h4jZaOwYtQTH"
      },
      "source": [
        "## RAG\n",
        "\n",
        "RAG consists of 3 parts:\n",
        "\n",
        "* Search\n",
        "* Prompt\n",
        "* LLM\n",
        "\n",
        "So in python it looks like that:\n",
        "```python\n",
        "def rag(query):\n",
        "    search_results = search(query)\n",
        "    prompt = build_prompt(query, search_results)\n",
        "    answer = llm(prompt)\n",
        "    return answer\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gjCbtnaIv5Dj",
      "metadata": {
        "id": "gjCbtnaIv5Dj"
      },
      "source": [
        "## The RAG flow\n",
        "\n",
        "We add a call to an LLM and combine everything into a complete RAG pipeline.\n",
        "\n",
        "Explanation:\n",
        "\n",
        "* build_prompt: Formats the search results into a prompt\n",
        "* llm: Makes the API call to the language model\n",
        "* rag: Combines search and LLM into a single function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1b9b61c3-45bf-4cbd-81b6-e939d1725fab",
      "metadata": {
        "id": "1b9b61c3-45bf-4cbd-81b6-e939d1725fab"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cbb5c60a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "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\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.getenv(\"OPENAI_API_KEY\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca6ee427",
      "metadata": {},
      "source": [
        "**NB: This cell will incur charges.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c9aacd83-ff31-4490-967f-a5b24abe8ccc",
      "metadata": {
        "id": "c9aacd83-ff31-4490-967f-a5b24abe8ccc"
      },
      "outputs": [],
      "source": [
        "def llm(prompt):\n",
        "    response = client.chat.completions.create(# Sends a prompt to the OpenAI API\n",
        "        model='gpt-4o-mini',\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    # Extracts the text content of the model's reply\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "def rag(query): # Implements the RAG workflow\n",
        "    search_results = search(query) # Searches FAQ database for relevant documents for the query\n",
        "    prompt = build_prompt(query, search_results) # Formats search results and query for the LLM\n",
        "    answer = llm(prompt) # Sends the formatted prompt to the LLM and gets the answer\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "817a30ea-5855-4143-9b1a-258b72e16550",
      "metadata": {
        "id": "817a30ea-5855-4143-9b1a-258b72e16550",
        "outputId": "68dd2f90-8390-4ecb-e69c-5425728dc9cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, you can still join the course now. Even if you don't register, you're eligible to submit the homeworks. However, be aware that there will be deadlines for turning in the final projects, so it's advisable not to leave everything until the last minute.\""
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag('I just discovered the course. Can I join now?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4c521c75-ccfd-46ee-938b-9dc742ead384",
      "metadata": {
        "id": "4c521c75-ccfd-46ee-938b-9dc742ead384",
        "outputId": "05dfefcb-5846-4e67-8246-a100726bea96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The provided context does not include specific instructions for running Docker on Gentoo. Therefore, I cannot provide an answer to the question based on the available information.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rag('how do I run docker on gentoo?')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5DVQ8_XKwkkT",
      "metadata": {
        "id": "5DVQ8_XKwkkT"
      },
      "source": [
        "# Part 1: Agentic RAG\n",
        "\n",
        "Now let's make our flow agentic\n",
        "\n",
        "## Agents and Agentic flows\n",
        "\n",
        "Agents are AI systems that can:\n",
        "\n",
        "* Make decisions about what actions to take\n",
        "* Use tools to accomplish tasks\n",
        "* Maintain state and context\n",
        "* Learn from previous interactions\n",
        "* Work towards specific goals\n",
        "\n",
        "Agentic flow is not necessarily a completely independent agent, but it can still make some decisions during the flow execution\n",
        "\n",
        "A typical agentic flow consists of:\n",
        "\n",
        "1. Receiving a user request\n",
        "2. Analyzing the request and available tools\n",
        "3. Deciding on the next action\n",
        "4. Executing the action using appropriate tools\n",
        "5. Evaluating the results\n",
        "6. Either completing the task or continuing with more actions\n",
        "\n",
        "The key difference from basic RAG is that agents can:\n",
        "\n",
        "* Make multiple search queries\n",
        "* Combine information from different sources\n",
        "* Decide when to stop searching\n",
        "* Use their own knowledge when appropriate\n",
        "* Chain multiple actions together\n",
        "So in agentic RAG, the system\n",
        "\n",
        "* has access to the history of previous actions\n",
        "* makes decisions independently based on the current information and the previous actions\n",
        "\n",
        "Let's implement this step by step.\n",
        "\n",
        "## Making RAG more agentic\n",
        "\n",
        "First, we'll take the prompt we have so far and make it a little more \"agentic\":\n",
        "\n",
        "* Tell the LLM that it can answer the question directly or look up context\n",
        "* Provide output templates\n",
        "* Show clearly what's the source of the answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "74e8d5d6-823f-42a3-b9a9-bb6137ae059c",
      "metadata": {
        "id": "74e8d5d6-823f-42a3-b9a9-bb6137ae059c"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"\n",
        "You're a course teaching assistant.\n",
        "\n",
        "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
        "At the beginning the context is EMPTY.\n",
        "\n",
        "<QUESTION>\n",
        "{question}\n",
        "</QUESTION>\n",
        "\n",
        "<CONTEXT>\n",
        "{context}\n",
        "</CONTEXT>\n",
        "\n",
        "If CONTEXT is EMPTY, you can use our FAQ database.\n",
        "In this case, use the following output template:\n",
        "\n",
        "{{\n",
        "\"action\": \"SEARCH\",\n",
        "\"reasoning\": \"<add your reasoning here>\"\n",
        "}}\n",
        "\n",
        "If you can answer the QUESTION using CONTEXT, use this template:\n",
        "\n",
        "{{\n",
        "\"action\": \"ANSWER\",\n",
        "\"answer\": \"<your answer>\",\n",
        "\"source\": \"CONTEXT\"\n",
        "}}\n",
        "\n",
        "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
        "\n",
        "{{\n",
        "\"action\": \"ANSWER\",\n",
        "\"answer\": \"<your answer>\",\n",
        "\"source\": \"OWN_KNOWLEDGE\"\n",
        "}}\n",
        "\"\"\".strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b10780a3-d684-4960-bf9c-b01014547ef9",
      "metadata": {
        "id": "b10780a3-d684-4960-bf9c-b01014547ef9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You're a course teaching assistant.\n",
            "\n",
            "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
            "At the beginning the context is EMPTY.\n",
            "\n",
            "<QUESTION>\n",
            "how do I run docker on gentoo?\n",
            "</QUESTION>\n",
            "\n",
            "<CONTEXT>\n",
            "EMPTY\n",
            "</CONTEXT>\n",
            "\n",
            "If CONTEXT is EMPTY, you can use our FAQ database.\n",
            "In this case, use the following output template:\n",
            "\n",
            "{\n",
            "\"action\": \"SEARCH\",\n",
            "\"reasoning\": \"<add your reasoning here>\"\n",
            "}\n",
            "\n",
            "If you can answer the QUESTION using CONTEXT, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"CONTEXT\"\n",
            "}\n",
            "\n",
            "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Let's use it:\n",
        "question = \"how do I run docker on gentoo?\"\n",
        "context = \"EMPTY\"\n",
        "\n",
        "prompt = prompt_template.format(question=question, context=context)\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59cec0c9",
      "metadata": {},
      "source": [
        "## Testing the prompt\n",
        "\n",
        "**Step-by-step flow:**\n",
        "\n",
        "**1. String Template:**\n",
        "\n",
        "- Above, `prompt_template` is defined as a string with placeholders for `{question}` and `{context}`.\n",
        "- It is filled using `prompt = prompt_template.format(question=question, context=context)`.\n",
        "\n",
        "**2. Calling llm(prompt):**\n",
        "\n",
        "- The `llm` function takes the formatted prompt and sends it to the OpenAI API using `client.chat.completions.create`.\n",
        "- This function wraps the API call, specifying the model and passing the prompt as a message.\n",
        "\n",
        "**3. OpenAI API:**\n",
        "\n",
        "- The API receives the prompt, generates a response, and returns it.\n",
        "\n",
        "**4. Extracting the Answer:**\n",
        "\n",
        "- The `llm` function extracts the answer text from the API response (`response.choices[0].message.content`) and returns it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4149b195-908a-4b6e-bdd8-658be48b8d3a",
      "metadata": {
        "id": "4149b195-908a-4b6e-bdd8-658be48b8d3a",
        "outputId": "83e7da53-6843-490c-c918-246222b3a4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"To run Docker on Gentoo, you need to follow these steps:\\n\\n1. **Install Docker**: You can install Docker using the Portage package manager. First, make sure your system is up to date, then run:\\n   ```\\n   emerge app-emulation/docker\\n   ```\\n\\n2. **Add your user to the Docker group**: This allows you to run Docker commands without sudo. Replace `yourusername` with your actual username:\\n   ```\\n   usermod -aG docker yourusername\\n   ```\\n   Then, log out and back in for the group change to take effect.\\n\\n3. **Start the Docker service**: Use the following commands to start Docker:\\n   ```\\n   rc-update add docker default\\n   service docker start\\n   ```\\n\\n4. **Check Docker version**: You can verify that Docker is installed correctly by checking the version:\\n   ```\\n   docker --version\\n   ```\\n\\n5. **Run a test container**: To confirm that Docker is working, you can run a simple test container:\\n   ```\\n   docker run hello-world\\n   ```\\n\\nIf the container runs successfully, Docker is set up correctly on your Gentoo system.\",\n",
            "\"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# We may get something like this:\n",
        "answer = llm(prompt) # Uses its own knowledge since the context is empty\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "P-qRENVNzBF3",
      "metadata": {
        "id": "P-qRENVNzBF3"
      },
      "outputs": [],
      "source": [
        "# But if we ask for something that it can't answer:\n",
        "question = \"how do I join the course?\" # Not covered by the FAQ context\n",
        "context = \"EMPTY\" \n",
        "\n",
        "prompt = prompt_template.format(question=question, context=context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "db6574e6-aded-43bd-9836-2e3d834c4341",
      "metadata": {
        "id": "db6574e6-aded-43bd-9836-2e3d834c4341",
        "outputId": "fb27bc28-a856-409b-f8a1-5a32dc7b55af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"To join the course, you typically need to register through the course's official website or platform where it is hosted. Look for a 'Sign Up' or 'Enroll' button, create an account if required, and follow the prompts to complete your enrollment. If you have any specific questions about joining, feel free to ask!\",\n",
            "\"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# We will get this:\n",
        "answer = llm(prompt)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5694d89b-eef9-4fe2-b7fe-93cf0fa4b27e",
      "metadata": {
        "id": "5694d89b-eef9-4fe2-b7fe-93cf0fa4b27e"
      },
      "outputs": [],
      "source": [
        "# Here, build_context is a helper function:\n",
        "def build_context(search_results):\n",
        "    context = \"\"\n",
        "    # Converts a list of FAQ search results into a formatted string\n",
        "    for doc in search_results:\n",
        "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
        "\n",
        "    return context.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "de0d0077-1a49-4670-ad2d-790b76a826ba",
      "metadata": {
        "id": "de0d0077-1a49-4670-ad2d-790b76a826ba",
        "outputId": "ac53fac0-5518-48f7-d60a-231d2bdbd9da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You're a course teaching assistant.\n",
            "\n",
            "You're given a QUESTION from a course student and that you need to answer with your own knowledge and provided CONTEXT.\n",
            "At the beginning the context is EMPTY.\n",
            "\n",
            "<QUESTION>\n",
            "how do I join the course?\n",
            "</QUESTION>\n",
            "\n",
            "<CONTEXT>\n",
            "section: General course-related questions\n",
            "question: Course - Can I still join the course after the start date?\n",
            "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
            "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Course - When will the course start?\n",
            "answer: The purpose of this document is to capture frequently asked technical questions\n",
            "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
            "Subscribe to course public Google Calendar (it works from Desktop only).\n",
            "Register before the course starts using this link.\n",
            "Join the course Telegram channel with announcements.\n",
            "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Course - Can I follow the course after it finishes?\n",
            "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
            "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
            "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
            "\n",
            "section: General course-related questions\n",
            "question: How do I use Git / GitHub for this course?\n",
            "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
            "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
            "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
            "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
            "This is also a great resource: https://dangitgit.com/\n",
            "</CONTEXT>\n",
            "\n",
            "If CONTEXT is EMPTY, you can use our FAQ database.\n",
            "In this case, use the following output template:\n",
            "\n",
            "{\n",
            "\"action\": \"SEARCH\",\n",
            "\"reasoning\": \"<add your reasoning here>\"\n",
            "}\n",
            "\n",
            "If you can answer the QUESTION using CONTEXT, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"CONTEXT\"\n",
            "}\n",
            "\n",
            "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Let's implement the search for relevant FAQ entries:\n",
        " # Queries FAQ database and returns a list of relevant documents\n",
        "search_results = search(question)\n",
        "# Formats results into a readable string, combining section, question, and answer for each document\n",
        "context = build_context(search_results) \n",
        "# Fill in the user question and queried formatted context to create a prompt for the LLM\n",
        "prompt = prompt_template.format(question=question, context=context)\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a1a9d8e6-ba16-405d-b879-028680a545aa",
      "metadata": {
        "id": "a1a9d8e6-ba16-405d-b879-028680a545aa",
        "outputId": "40a2b3b3-c638-4551-d5b8-48093fb9e25e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"To join the course, you need to register before the course starts using the provided registration link. The course begins on January 15, 2024, at 17:00. You should also join the course's Telegram channel for announcements and register on DataTalks.Club's Slack to stay connected with fellow participants and instructors.\",\n",
            "\"source\": \"CONTEXT\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Sends formatted prompt to OpenAI with user question and context built from FAQ search results\n",
        "answer = llm(prompt)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b06mWOPc0qIp",
      "metadata": {
        "id": "b06mWOPc0qIp"
      },
      "source": [
        "Let's put this together:\n",
        "\n",
        "* First attempt to answer it with our knowledge\n",
        "* If needed, do the lookup and then answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "30fa9499-9e9e-4630-8926-1d515b6473bb",
      "metadata": {
        "id": "30fa9499-9e9e-4630-8926-1d515b6473bb"
      },
      "outputs": [],
      "source": [
        "def agentic_rag_v1(question):\n",
        "    context = \"EMPTY\" # Initial context is empty\n",
        "    prompt = prompt_template.format(question=question, context=context) # Build the initial prompt\n",
        "    answer_json = llm(prompt) # Send prompt to LLM\n",
        "    answer = json.loads(answer_json) # The answer is parsed from JSON\n",
        "    print(answer)\n",
        "    # Check LLM’s action\n",
        "    if answer['action'] == 'SEARCH': # If the LLM says to search, proceed to the next step\n",
        "        print('need to perform search...')\n",
        "        # Perform search and build context\n",
        "        search_results = search(question) \n",
        "        context = build_context(search_results)\n",
        "        # Build a new prompt now including the context from the search\n",
        "        prompt = prompt_template.format(question=question, context=context)\n",
        "        answer_json = llm(prompt)\n",
        "        answer = json.loads(answer_json)\n",
        "        print(answer)\n",
        "    # Returns answer either from own knowledge or from the FAQ context\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d0181a69-51db-4c82-9bd7-263a075bb7c7",
      "metadata": {
        "id": "d0181a69-51db-4c82-9bd7-263a075bb7c7",
        "outputId": "5e900c01-27d6-4cce-91b6-d29fce8c0cfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'action': 'SEARCH', 'reasoning': 'The context is empty and I need to find information on how to join the course.'}\n",
            "need to perform search...\n",
            "{'action': 'ANSWER', 'answer': \"To join the course, you need to register using the provided link before the course starts. You can also join the Telegram channel for announcements and make sure to subscribe to the course's public Google Calendar to keep track of important dates and events. Don't forget to create an account on DataTalks.Club's Slack and join the relevant channel.\", 'source': 'CONTEXT'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'action': 'ANSWER',\n",
              " 'answer': \"To join the course, you need to register using the provided link before the course starts. You can also join the Telegram channel for announcements and make sure to subscribe to the course's public Google Calendar to keep track of important dates and events. Don't forget to create an account on DataTalks.Club's Slack and join the relevant channel.\",\n",
              " 'source': 'CONTEXT'}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test it ('OWN_KNOWLEDGE' means the LLM couldn't find relevant information in the FAQ context):\n",
        "agentic_rag_v1('how do I join the course?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1f0e02cf-1088-46c2-b788-d27940d1617b",
      "metadata": {
        "id": "1f0e02cf-1088-46c2-b788-d27940d1617b",
        "outputId": "5be71e06-ccc6-40ea-895b-783beac32b65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'action': 'ANSWER', 'answer': \"To patch KDE under FreeBSD, follow these steps: \\n\\n1. **Obtain the Source Code**: You can typically get the source code for KDE from the FreeBSD Ports Collection. Navigate to the KDE port you want to patch. For instance, if you're interested in 'kde5', you can find it under `/usr/ports/x11/kde5`.\\n\\n2. **Download the Patch**: Get the patch file you want to apply. This might be available from KDE's official bug tracker, Git repositories, or relevant developer forums.\\n\\n3. **Apply the Patch**: Once you have the patch file, use the `patch` command to apply it. For example:\\n   ```\\n   cd /usr/ports/x11/kde5\\n   patch < /path/to/your/patch/file.patch\\n   ```\\n\\n4. **Make and Install**: After applying the patch, you need to rebuild and reinstall the port to ensure your changes take effect. You can do this using:\\n   ```\\n   make clean install\\n   ```\\n\\n5. **Test the Changes**: Run KDE to see if your patch resolves the issue or adds the desired functionality.\\n\\nAlways remember to check if there are any specific instructions provided with the patch you are applying, as some patches may require additional steps or configurations.\", 'source': 'OWN_KNOWLEDGE'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'action': 'ANSWER',\n",
              " 'answer': \"To patch KDE under FreeBSD, follow these steps: \\n\\n1. **Obtain the Source Code**: You can typically get the source code for KDE from the FreeBSD Ports Collection. Navigate to the KDE port you want to patch. For instance, if you're interested in 'kde5', you can find it under `/usr/ports/x11/kde5`.\\n\\n2. **Download the Patch**: Get the patch file you want to apply. This might be available from KDE's official bug tracker, Git repositories, or relevant developer forums.\\n\\n3. **Apply the Patch**: Once you have the patch file, use the `patch` command to apply it. For example:\\n   ```\\n   cd /usr/ports/x11/kde5\\n   patch < /path/to/your/patch/file.patch\\n   ```\\n\\n4. **Make and Install**: After applying the patch, you need to rebuild and reinstall the port to ensure your changes take effect. You can do this using:\\n   ```\\n   make clean install\\n   ```\\n\\n5. **Test the Changes**: Run KDE to see if your patch resolves the issue or adds the desired functionality.\\n\\nAlways remember to check if there are any specific instructions provided with the patch you are applying, as some patches may require additional steps or configurations.\",\n",
              " 'source': 'OWN_KNOWLEDGE'}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agentic_rag_v1('how patch KDE under FreeBSD?')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34be6bcf-e7ff-492c-8f62-3025742bce5f",
      "metadata": {
        "id": "34be6bcf-e7ff-492c-8f62-3025742bce5f"
      },
      "source": [
        "# Part 2: Agentic search\n",
        "\n",
        "So far we had two actions only: search and answer.\n",
        "\n",
        "But we can let our \"agent\" formulate one or more search queries - and do it for a few iterations until we found an answer\n",
        "\n",
        "Let's build a prompt:\n",
        "\n",
        "* List available actions:\n",
        "  * Search in FAQ\n",
        "  * Answer using own knowledge\n",
        "  * Answer using information extracted from FAQ\n",
        "* Provide access to the previous actions\n",
        "* Have clear stop criteria (no more than X iterations)\n",
        "* We also specify the output format, so it's easier to parse it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "87973665-b4f3-4a96-b3a5-8bb0edb57a5b",
      "metadata": {
        "id": "87973665-b4f3-4a96-b3a5-8bb0edb57a5b"
      },
      "outputs": [],
      "source": [
        "prompt_template = \"\"\"\n",
        "You're a course teaching assistant.\n",
        "\n",
        "You're given a QUESTION from a course student that you need to answer with your own knowledge and provided CONTEXT.\n",
        "\n",
        "The CONTEXT is built with the documents from our FAQ database.\n",
        "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
        "from FAQ to add them to the context.\n",
        "PREVIOUS_ACTIONS contains the actions you already performed.\n",
        "\n",
        "At the beginning the CONTEXT is empty.\n",
        "\n",
        "You can perform the following actions:\n",
        "\n",
        "- Search in the FAQ database to get more data for the CONTEXT\n",
        "- Answer the question using the CONTEXT\n",
        "- Answer the question using your own knowledge\n",
        "\n",
        "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
        "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
        "\n",
        "Don't use search queries used at the previous iterations.\n",
        "\n",
        "\n",
        "Don't repeat previously performed actions.\n",
        "\n",
        "Don't perform more than {max_iterations} iterations for a given student question.\n",
        "The current iteration number: {iteration_number}. If we exceed the allowed number\n",
        "of iterations, give the best possible answer with the provided information.\n",
        "\n",
        "\n",
        "Output templates:\n",
        "\n",
        "If you want to perform search, use this template:\n",
        "\n",
        "{{\n",
        "\"action\": \"SEARCH\",\n",
        "\"reasoning\": \"<add your reasoning here>\",\n",
        "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
        "}}\n",
        "\n",
        "If you can answer the QUESTION using CONTEXT, use this template:\n",
        "\n",
        "{{\n",
        "\"action\": \"ANSWER_CONTEXT\",\n",
        "\"answer\": \"<your answer>\",\n",
        "\"source\": \"CONTEXT\"\n",
        "}}\n",
        "\n",
        "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
        "\n",
        "{{\n",
        "\"action\": \"ANSWER\",\n",
        "\"answer\": \"<your answer>\",\n",
        "\"source\": \"OWN_KNOWLEDGE\"\n",
        "}}\n",
        "\n",
        "\n",
        "<QUESTION>\n",
        "{question}\n",
        "</QUESTION>\n",
        "\n",
        "<SEARCH_QUERIES>\n",
        "{search_queries}\n",
        "</SEARCH_QUERIES>\n",
        "\n",
        "<CONTEXT>\n",
        "{context}\n",
        "</CONTEXT>\n",
        "\n",
        "<PREVIOUS_ACTIONS>\n",
        "{previous_actions}\n",
        "</PREVIOUS_ACTIONS>\n",
        "\"\"\".strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5e7f39f7-aeb6-42fa-b010-0b366f19967c",
      "metadata": {
        "id": "5e7f39f7-aeb6-42fa-b010-0b366f19967c",
        "outputId": "6191229d-03b4-47eb-fd7c-6aaecb61e969"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You're a course teaching assistant.\n",
            "\n",
            "You're given a QUESTION from a course student that you need to answer with your own knowledge and provided CONTEXT.\n",
            "\n",
            "The CONTEXT is built with the documents from our FAQ database.\n",
            "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
            "from FAQ to add them to the context.\n",
            "PREVIOUS_ACTIONS contains the actions you already performed.\n",
            "\n",
            "At the beginning the CONTEXT is empty.\n",
            "\n",
            "You can perform the following actions:\n",
            "\n",
            "- Search in the FAQ database to get more data for the CONTEXT\n",
            "- Answer the question using the CONTEXT\n",
            "- Answer the question using your own knowledge\n",
            "\n",
            "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
            "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
            "\n",
            "Don't use search queries used at the previous iterations.\n",
            "\n",
            "\n",
            "Don't repeat previously performed actions.\n",
            "\n",
            "Don't perform more than 3 iterations for a given student question.\n",
            "The current iteration number: 1. If we exceed the allowed number\n",
            "of iterations, give the best possible answer with the provided information.\n",
            "\n",
            "\n",
            "Output templates:\n",
            "\n",
            "If you want to perform search, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"SEARCH\",\n",
            "\"reasoning\": \"<add your reasoning here>\",\n",
            "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
            "}\n",
            "\n",
            "If you can answer the QUESTION using CONTEXT, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER_CONTEXT\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"CONTEXT\"\n",
            "}\n",
            "\n",
            "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n",
            "\n",
            "\n",
            "<QUESTION>\n",
            "how do I join the course?\n",
            "</QUESTION>\n",
            "\n",
            "<SEARCH_QUERIES>\n",
            "\n",
            "</SEARCH_QUERIES>\n",
            "\n",
            "<CONTEXT>\n",
            "\n",
            "</CONTEXT>\n",
            "\n",
            "<PREVIOUS_ACTIONS>\n",
            "\n",
            "</PREVIOUS_ACTIONS>\n"
          ]
        }
      ],
      "source": [
        "# Our code becomes more complicated. For the first iteration, we have:\n",
        "question = \"how do I join the course?\"\n",
        "# Track search queries, search results, and previous actions to keep history and avoid repeating searches/actions.\n",
        "search_queries = []\n",
        "search_results = []\n",
        "previous_actions = []\n",
        "# Builds the (empty) context string from the current search results\n",
        "context = build_context(search_results)\n",
        "\n",
        "# Fills in question, context, search queries, previous actions, and iteration info (what it knows so far and what it can do next).\n",
        "prompt = prompt_template.format(\n",
        "    question=question,\n",
        "    context=context,\n",
        "    search_queries=\"\\n\".join(search_queries),\n",
        "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
        "    max_iterations=3,\n",
        "    iteration_number=1\n",
        ")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "29f5989b-949f-478a-abea-048b1bcfa1f5",
      "metadata": {
        "id": "29f5989b-949f-478a-abea-048b1bcfa1f5"
      },
      "outputs": [],
      "source": [
        "answer_json = llm(prompt)\n",
        "answer = json.loads(answer_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "95372972-6767-4c98-ba68-57a45326918f",
      "metadata": {
        "id": "95372972-6767-4c98-ba68-57a45326918f"
      },
      "outputs": [],
      "source": [
        "# We need to save the actions (Tracks the agent’s decision history for future iterations and prompt construction):\n",
        "previous_actions.append(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d4097b3d-2d46-4ba0-9444-da92d604cd7f",
      "metadata": {
        "id": "d4097b3d-2d46-4ba0-9444-da92d604cd7f",
        "outputId": "556aeaaa-71c7-46f7-a66d-70ffb974d9dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"action\": \"SEARCH\",\n",
            "  \"reasoning\": \"The context does not contain any information about how to join the course. I need to search for details regarding the enrollment or registration process for the course.\",\n",
            "  \"keywords\": [\n",
            "    \"how to enroll in the course\",\n",
            "    \"course registration process\",\n",
            "    \"joining the course instructions\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Output:\n",
        "print(json.dumps(answer, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f9d091f8-8765-4012-971e-ad4498cab7aa",
      "metadata": {
        "id": "f9d091f8-8765-4012-971e-ad4498cab7aa"
      },
      "outputs": [],
      "source": [
        "# Keeps a record of all search queries so far to avoid duplicate searches and informing the next prompt\n",
        "keywords = answer['keywords']\n",
        "search_queries.extend(keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "08d93d61-5762-435d-a388-19c71010b321",
      "metadata": {
        "id": "08d93d61-5762-435d-a388-19c71010b321"
      },
      "outputs": [],
      "source": [
        "# For each keyword call search() to query the FAQ database\n",
        "for k in keywords:\n",
        "    res = search(k)\n",
        "    search_results.extend(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "f35dfffd-82ec-492c-acf1-e7245a80578d",
      "metadata": {
        "id": "f35dfffd-82ec-492c-acf1-e7245a80578d"
      },
      "outputs": [],
      "source": [
        "# Some of the search results will be duplicates, so we need to remove them:\n",
        "def dedup(seq):\n",
        "    seen = set()\n",
        "    result = []\n",
        "    for el in seq:\n",
        "        _id = el['_id'] \n",
        "        # If the ID is already seen, skip this element\n",
        "        if _id in seen:\n",
        "            continue\n",
        "        seen.add(_id)\n",
        "        result.append(el)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "ddb8a453-60a4-436d-a4db-10191cf3c1ca",
      "metadata": {
        "id": "ddb8a453-60a4-436d-a4db-10191cf3c1ca"
      },
      "outputs": [],
      "source": [
        "search_results = dedup(search_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d3eaa30b-edc7-449a-a6cd-b80f6081b862",
      "metadata": {
        "id": "d3eaa30b-edc7-449a-a6cd-b80f6081b862",
        "outputId": "0a1cad8b-0510-48e2-b335-6f888e360590",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You're a course teaching assistant.\n",
            "\n",
            "You're given a QUESTION from a course student that you need to answer with your own knowledge and provided CONTEXT.\n",
            "\n",
            "The CONTEXT is built with the documents from our FAQ database.\n",
            "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
            "from FAQ to add them to the context.\n",
            "PREVIOUS_ACTIONS contains the actions you already performed.\n",
            "\n",
            "At the beginning the CONTEXT is empty.\n",
            "\n",
            "You can perform the following actions:\n",
            "\n",
            "- Search in the FAQ database to get more data for the CONTEXT\n",
            "- Answer the question using the CONTEXT\n",
            "- Answer the question using your own knowledge\n",
            "\n",
            "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
            "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
            "\n",
            "Don't use search queries used at the previous iterations.\n",
            "\n",
            "\n",
            "Don't repeat previously performed actions.\n",
            "\n",
            "Don't perform more than 3 iterations for a given student question.\n",
            "The current iteration number: 2. If we exceed the allowed number\n",
            "of iterations, give the best possible answer with the provided information.\n",
            "\n",
            "\n",
            "Output templates:\n",
            "\n",
            "If you want to perform search, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"SEARCH\",\n",
            "\"reasoning\": \"<add your reasoning here>\",\n",
            "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
            "}\n",
            "\n",
            "If you can answer the QUESTION using CONTEXT, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER_CONTEXT\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"CONTEXT\"\n",
            "}\n",
            "\n",
            "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n",
            "\n",
            "\n",
            "<QUESTION>\n",
            "how do I join the course?\n",
            "</QUESTION>\n",
            "\n",
            "<SEARCH_QUERIES>\n",
            "how to enroll in the course\n",
            "course registration process\n",
            "joining the course instructions\n",
            "</SEARCH_QUERIES>\n",
            "\n",
            "<CONTEXT>\n",
            "section: General course-related questions\n",
            "question: Course - When will the course start?\n",
            "answer: The purpose of this document is to capture frequently asked technical questions\n",
            "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
            "Subscribe to course public Google Calendar (it works from Desktop only).\n",
            "Register before the course starts using this link.\n",
            "Join the course Telegram channel with announcements.\n",
            "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Course - Can I follow the course after it finishes?\n",
            "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
            "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
            "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
            "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
            "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
            "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
            "\n",
            "section: General course-related questions\n",
            "question: How do I use Git / GitHub for this course?\n",
            "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
            "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
            "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
            "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
            "This is also a great resource: https://dangitgit.com/\n",
            "\n",
            "section: Module 5: pyspark\n",
            "question: lsRuntimeError: Java gateway process exited before sending its port number\n",
            "answer: After installing all including pyspark (and it is successfully imported), but then running this script on the jupyter notebook\n",
            "import pyspark\n",
            "from pyspark.sql import SparkSession\n",
            "spark = SparkSession.builder \\\n",
            ".master(\"local[*]\") \\\n",
            ".appName('test') \\\n",
            ".getOrCreate()\n",
            "df = spark.read \\\n",
            ".option(\"header\", \"true\") \\\n",
            ".csv('taxi+_zone_lookup.csv')\n",
            "df.show()\n",
            "it gives the error:\n",
            "RuntimeError: Java gateway process exited before sending its port number\n",
            "✅The solution (for me) was:\n",
            "pip install findspark on the command line and then\n",
            "Add\n",
            "import findspark\n",
            "findspark.init()\n",
            "to the top of the script.\n",
            "Another possible solution is:\n",
            "Check that pyspark is pointing to the correct location.\n",
            "Run pyspark.__file__. It should be list /home/<your user name>/spark/spark-3.0.3-bin-hadoop3.2/python/pyspark/__init__.py if you followed the videos.\n",
            "If it is pointing to your python site-packages remove the pyspark directory there and check that you have added the correct exports to you .bashrc file and that there are not any other exports which might supersede the ones provided in the course content.\n",
            "To add to the solution above, if the errors persist in regards to setting the correct path for spark,  an alternative solution for permanent path setting solve the error is  to set environment variables on system and user environment variables following this tutorial: Install Apache PySpark on Windows PC | Apache Spark Installation Guide\n",
            "Once everything is installed, skip to 7:14 to set up environment variables. This allows for the environment variables to be set permanently.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?\n",
            "answer: You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\n",
            "</CONTEXT>\n",
            "\n",
            "<PREVIOUS_ACTIONS>\n",
            "{\"action\": \"SEARCH\", \"reasoning\": \"The context does not contain any information about how to join the course. I need to search for details regarding the enrollment or registration process for the course.\", \"keywords\": [\"how to enroll in the course\", \"course registration process\", \"joining the course instructions\"]}\n",
            "</PREVIOUS_ACTIONS>\n"
          ]
        }
      ],
      "source": [
        "# Now let's make another iteration - use the same code as previously, but remove variable initialization and increase the iteration number:\n",
        "# The first iteration starts the agentic loop with empty history; this iteration continues the loop, carrying over results and actions from previous steps.\n",
        "# question = \"how do I join the course?\"\n",
        "\n",
        "# search_queries = []\n",
        "# search_results = []\n",
        "# previous_actions = []\n",
        "\n",
        "context = build_context(search_results)\n",
        "\n",
        "prompt = prompt_template.format(\n",
        "    question=question,\n",
        "    context=context,\n",
        "    search_queries=\"\\n\".join(search_queries),\n",
        "    previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
        "    max_iterations=3,\n",
        "    iteration_number=2\n",
        ")\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ff78c687-a2c2-439b-a0af-19fbc09d94b4",
      "metadata": {
        "id": "ff78c687-a2c2-439b-a0af-19fbc09d94b4",
        "outputId": "80a4b232-c0af-4037-e0c4-9e203248af8f",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"action\": \"ANSWER_CONTEXT\",\n",
            "  \"answer\": \"To join the course, you need to register before the course starts using the provided registration link. You can also start learning and submitting homework without formally registering, as registration is mainly to gauge interest prior to the start date. The course is set to begin on January 15, 2024, at 17:00, starting with live Office Hours.\",\n",
            "  \"source\": \"CONTEXT\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "answer_json = llm(prompt)\n",
        "answer = json.loads(answer_json)\n",
        "print(json.dumps(answer, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "652db0b9-fbdd-4df5-b973-ac6cc0711213",
      "metadata": {
        "id": "652db0b9-fbdd-4df5-b973-ac6cc0711213",
        "outputId": "5497fcb3-7c12-4e7c-bb39-f93c78355982",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ITERATION #0...\n",
            "You're a course teaching assistant.\n",
            "\n",
            "You're given a QUESTION from a course student that you need to answer with your own knowledge and provided CONTEXT.\n",
            "\n",
            "The CONTEXT is built with the documents from our FAQ database.\n",
            "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
            "from FAQ to add them to the context.\n",
            "PREVIOUS_ACTIONS contains the actions you already performed.\n",
            "\n",
            "At the beginning the CONTEXT is empty.\n",
            "\n",
            "You can perform the following actions:\n",
            "\n",
            "- Search in the FAQ database to get more data for the CONTEXT\n",
            "- Answer the question using the CONTEXT\n",
            "- Answer the question using your own knowledge\n",
            "\n",
            "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
            "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
            "\n",
            "Don't use search queries used at the previous iterations.\n",
            "\n",
            "\n",
            "Don't repeat previously performed actions.\n",
            "\n",
            "Don't perform more than 3 iterations for a given student question.\n",
            "The current iteration number: 0. If we exceed the allowed number\n",
            "of iterations, give the best possible answer with the provided information.\n",
            "\n",
            "\n",
            "Output templates:\n",
            "\n",
            "If you want to perform search, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"SEARCH\",\n",
            "\"reasoning\": \"<add your reasoning here>\",\n",
            "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
            "}\n",
            "\n",
            "If you can answer the QUESTION using CONTEXT, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER_CONTEXT\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"CONTEXT\"\n",
            "}\n",
            "\n",
            "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n",
            "\n",
            "\n",
            "<QUESTION>\n",
            "what do I need to do to be successful at module 1?\n",
            "</QUESTION>\n",
            "\n",
            "<SEARCH_QUERIES>\n",
            "\n",
            "</SEARCH_QUERIES>\n",
            "\n",
            "<CONTEXT>\n",
            "\n",
            "</CONTEXT>\n",
            "\n",
            "<PREVIOUS_ACTIONS>\n",
            "\n",
            "</PREVIOUS_ACTIONS>\n",
            "{\n",
            "  \"action\": \"SEARCH\",\n",
            "  \"reasoning\": \"I want to gather specific information about success strategies or tips related to Module 1 to provide the student with relevant advice.\",\n",
            "  \"keywords\": [\n",
            "    \"success tips Module 1\",\n",
            "    \"how to succeed Module 1\",\n",
            "    \"Module 1 study strategies\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "ITERATION #1...\n",
            "You're a course teaching assistant.\n",
            "\n",
            "You're given a QUESTION from a course student that you need to answer with your own knowledge and provided CONTEXT.\n",
            "\n",
            "The CONTEXT is built with the documents from our FAQ database.\n",
            "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
            "from FAQ to add them to the context.\n",
            "PREVIOUS_ACTIONS contains the actions you already performed.\n",
            "\n",
            "At the beginning the CONTEXT is empty.\n",
            "\n",
            "You can perform the following actions:\n",
            "\n",
            "- Search in the FAQ database to get more data for the CONTEXT\n",
            "- Answer the question using the CONTEXT\n",
            "- Answer the question using your own knowledge\n",
            "\n",
            "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
            "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
            "\n",
            "Don't use search queries used at the previous iterations.\n",
            "\n",
            "\n",
            "Don't repeat previously performed actions.\n",
            "\n",
            "Don't perform more than 3 iterations for a given student question.\n",
            "The current iteration number: 1. If we exceed the allowed number\n",
            "of iterations, give the best possible answer with the provided information.\n",
            "\n",
            "\n",
            "Output templates:\n",
            "\n",
            "If you want to perform search, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"SEARCH\",\n",
            "\"reasoning\": \"<add your reasoning here>\",\n",
            "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
            "}\n",
            "\n",
            "If you can answer the QUESTION using CONTEXT, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER_CONTEXT\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"CONTEXT\"\n",
            "}\n",
            "\n",
            "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n",
            "\n",
            "\n",
            "<QUESTION>\n",
            "what do I need to do to be successful at module 1?\n",
            "</QUESTION>\n",
            "\n",
            "<SEARCH_QUERIES>\n",
            "Module 1 study strategies\n",
            "success tips Module 1\n",
            "how to succeed Module 1\n",
            "</SEARCH_QUERIES>\n",
            "\n",
            "<CONTEXT>\n",
            "section: Module 5: pyspark\n",
            "question: Module Not Found Error in Jupyter Notebook .\n",
            "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
            "The solution which worked for me(use following in jupyter notebook) :\n",
            "!pip install findspark\n",
            "import findspark\n",
            "findspark.init()\n",
            "Thereafter , import pyspark and create spark contex<<t as usual\n",
            "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
            "Filter based on conditions based on multiple columns\n",
            "from pyspark.sql.functions import col\n",
            "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
            "Krishna Anand\n",
            "\n",
            "section: Module 5: pyspark\n",
            "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
            "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
            "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
            "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
            "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
            "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
            "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
            "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
            "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
            "\n",
            "section: Module 4: analytics engineering with dbt\n",
            "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
            "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
            "Solution:\n",
            "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
            "\n",
            "section: Module 1: Docker and Terraform\n",
            "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
            "answer: Issue:\n",
            "e…\n",
            "Solution:\n",
            "pip install psycopg2-binary\n",
            "If you already have it, you might need to update it:\n",
            "pip install psycopg2-binary --upgrade\n",
            "Other methods, if the above fails:\n",
            "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
            "First uninstall the psycopg package\n",
            "Then update conda or pip\n",
            "Then install psycopg again using pip.\n",
            "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
            "\n",
            "section: Module 1: Docker and Terraform\n",
            "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
            "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
            "Solution:\n",
            "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
            "engine = create_engine(conn_string)\n",
            "</CONTEXT>\n",
            "\n",
            "<PREVIOUS_ACTIONS>\n",
            "{\"action\": \"SEARCH\", \"reasoning\": \"I want to gather specific information about success strategies or tips related to Module 1 to provide the student with relevant advice.\", \"keywords\": [\"success tips Module 1\", \"how to succeed Module 1\", \"Module 1 study strategies\"]}\n",
            "</PREVIOUS_ACTIONS>\n",
            "{\n",
            "  \"action\": \"SEARCH\",\n",
            "  \"reasoning\": \"To provide a more comprehensive response regarding strategies for succeeding in Module 1, I need to find specific tips, techniques, or advice related to this module.\",\n",
            "  \"keywords\": [\n",
            "    \"Module 1 study tips\",\n",
            "    \"how to excel Module 1\",\n",
            "    \"Module 1 resources\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "ITERATION #2...\n",
            "You're a course teaching assistant.\n",
            "\n",
            "You're given a QUESTION from a course student that you need to answer with your own knowledge and provided CONTEXT.\n",
            "\n",
            "The CONTEXT is built with the documents from our FAQ database.\n",
            "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
            "from FAQ to add them to the context.\n",
            "PREVIOUS_ACTIONS contains the actions you already performed.\n",
            "\n",
            "At the beginning the CONTEXT is empty.\n",
            "\n",
            "You can perform the following actions:\n",
            "\n",
            "- Search in the FAQ database to get more data for the CONTEXT\n",
            "- Answer the question using the CONTEXT\n",
            "- Answer the question using your own knowledge\n",
            "\n",
            "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
            "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
            "\n",
            "Don't use search queries used at the previous iterations.\n",
            "\n",
            "\n",
            "Don't repeat previously performed actions.\n",
            "\n",
            "Don't perform more than 3 iterations for a given student question.\n",
            "The current iteration number: 2. If we exceed the allowed number\n",
            "of iterations, give the best possible answer with the provided information.\n",
            "\n",
            "\n",
            "Output templates:\n",
            "\n",
            "If you want to perform search, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"SEARCH\",\n",
            "\"reasoning\": \"<add your reasoning here>\",\n",
            "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
            "}\n",
            "\n",
            "If you can answer the QUESTION using CONTEXT, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER_CONTEXT\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"CONTEXT\"\n",
            "}\n",
            "\n",
            "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n",
            "\n",
            "\n",
            "<QUESTION>\n",
            "what do I need to do to be successful at module 1?\n",
            "</QUESTION>\n",
            "\n",
            "<SEARCH_QUERIES>\n",
            "Module 1 resources\n",
            "success tips Module 1\n",
            "Module 1 study strategies\n",
            "how to excel Module 1\n",
            "Module 1 study tips\n",
            "how to succeed Module 1\n",
            "</SEARCH_QUERIES>\n",
            "\n",
            "<CONTEXT>\n",
            "section: Module 5: pyspark\n",
            "question: Module Not Found Error in Jupyter Notebook .\n",
            "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
            "The solution which worked for me(use following in jupyter notebook) :\n",
            "!pip install findspark\n",
            "import findspark\n",
            "findspark.init()\n",
            "Thereafter , import pyspark and create spark contex<<t as usual\n",
            "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
            "Filter based on conditions based on multiple columns\n",
            "from pyspark.sql.functions import col\n",
            "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
            "Krishna Anand\n",
            "\n",
            "section: Module 5: pyspark\n",
            "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
            "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
            "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
            "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
            "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
            "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
            "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
            "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
            "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
            "\n",
            "section: Module 4: analytics engineering with dbt\n",
            "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
            "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
            "Solution:\n",
            "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
            "\n",
            "section: Module 1: Docker and Terraform\n",
            "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
            "answer: Issue:\n",
            "e…\n",
            "Solution:\n",
            "pip install psycopg2-binary\n",
            "If you already have it, you might need to update it:\n",
            "pip install psycopg2-binary --upgrade\n",
            "Other methods, if the above fails:\n",
            "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
            "First uninstall the psycopg package\n",
            "Then update conda or pip\n",
            "Then install psycopg again using pip.\n",
            "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
            "\n",
            "section: Module 1: Docker and Terraform\n",
            "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
            "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
            "Solution:\n",
            "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
            "engine = create_engine(conn_string)\n",
            "\n",
            "section: Module 6: streaming with kafka\n",
            "question: data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing\n",
            "answer: Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv\n",
            "\n",
            "section: Module 1: Docker and Terraform\n",
            "question: WSL - Insufficient system resources exist to complete the requested service.\n",
            "answer: Cause:\n",
            "It happens because the apps are not updated. To be specific, search for any pending updates for Windows Terminal, WSL and Windows Security updates.\n",
            "Solution\n",
            "for updating Windows terminal which worked for me:\n",
            "Go to Microsoft Store.\n",
            "Go to the library of apps installed in your system.\n",
            "Search for Windows terminal.\n",
            "Update the app and restart your system to  see the changes.\n",
            "For updating the Windows security updates:\n",
            "Go to Windows updates and check if there are any pending updates from Windows, especially security updates.\n",
            "Do restart your system once the updates are downloaded and installed successfully.\n",
            "</CONTEXT>\n",
            "\n",
            "<PREVIOUS_ACTIONS>\n",
            "{\"action\": \"SEARCH\", \"reasoning\": \"I want to gather specific information about success strategies or tips related to Module 1 to provide the student with relevant advice.\", \"keywords\": [\"success tips Module 1\", \"how to succeed Module 1\", \"Module 1 study strategies\"]}\n",
            "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a more comprehensive response regarding strategies for succeeding in Module 1, I need to find specific tips, techniques, or advice related to this module.\", \"keywords\": [\"Module 1 study tips\", \"how to excel Module 1\", \"Module 1 resources\"]}\n",
            "</PREVIOUS_ACTIONS>\n",
            "{\n",
            "  \"action\": \"SEARCH\",\n",
            "  \"reasoning\": \"I want to explore any additional specific techniques or tips that may help a student improve their chances of success in Module 1, focusing on study habits and effective learning strategies.\",\n",
            "  \"keywords\": [\n",
            "    \"Module 1 learning strategies\",\n",
            "    \"Module 1 success techniques\",\n",
            "    \"how to study effectively for Module 1\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "ITERATION #3...\n",
            "You're a course teaching assistant.\n",
            "\n",
            "You're given a QUESTION from a course student that you need to answer with your own knowledge and provided CONTEXT.\n",
            "\n",
            "The CONTEXT is built with the documents from our FAQ database.\n",
            "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
            "from FAQ to add them to the context.\n",
            "PREVIOUS_ACTIONS contains the actions you already performed.\n",
            "\n",
            "At the beginning the CONTEXT is empty.\n",
            "\n",
            "You can perform the following actions:\n",
            "\n",
            "- Search in the FAQ database to get more data for the CONTEXT\n",
            "- Answer the question using the CONTEXT\n",
            "- Answer the question using your own knowledge\n",
            "\n",
            "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
            "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
            "\n",
            "Don't use search queries used at the previous iterations.\n",
            "\n",
            "\n",
            "Don't repeat previously performed actions.\n",
            "\n",
            "Don't perform more than 3 iterations for a given student question.\n",
            "The current iteration number: 3. If we exceed the allowed number\n",
            "of iterations, give the best possible answer with the provided information.\n",
            "\n",
            "\n",
            "Output templates:\n",
            "\n",
            "If you want to perform search, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"SEARCH\",\n",
            "\"reasoning\": \"<add your reasoning here>\",\n",
            "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
            "}\n",
            "\n",
            "If you can answer the QUESTION using CONTEXT, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER_CONTEXT\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"CONTEXT\"\n",
            "}\n",
            "\n",
            "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n",
            "\n",
            "\n",
            "<QUESTION>\n",
            "what do I need to do to be successful at module 1?\n",
            "</QUESTION>\n",
            "\n",
            "<SEARCH_QUERIES>\n",
            "Module 1 resources\n",
            "how to excel Module 1\n",
            "success tips Module 1\n",
            "Module 1 learning strategies\n",
            "Module 1 success techniques\n",
            "how to succeed Module 1\n",
            "how to study effectively for Module 1\n",
            "Module 1 study strategies\n",
            "Module 1 study tips\n",
            "</SEARCH_QUERIES>\n",
            "\n",
            "<CONTEXT>\n",
            "section: Module 5: pyspark\n",
            "question: Module Not Found Error in Jupyter Notebook .\n",
            "answer: Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\n",
            "The solution which worked for me(use following in jupyter notebook) :\n",
            "!pip install findspark\n",
            "import findspark\n",
            "findspark.init()\n",
            "Thereafter , import pyspark and create spark contex<<t as usual\n",
            "None of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\n",
            "Filter based on conditions based on multiple columns\n",
            "from pyspark.sql.functions import col\n",
            "new_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\n",
            "Krishna Anand\n",
            "\n",
            "section: Module 5: pyspark\n",
            "question: Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\n",
            "answer: You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\n",
            "` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\n",
            "export PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\n",
            "Make sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\n",
            "For instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\n",
            "Then the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\n",
            "Additionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\n",
            "~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\n",
            "\n",
            "section: Module 4: analytics engineering with dbt\n",
            "question: DBT - Error: No module named 'pytz' while setting up dbt with docker\n",
            "answer: Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\n",
            "Solution:\n",
            "Add `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\n",
            "\n",
            "section: Module 1: Docker and Terraform\n",
            "question: Postgres - ModuleNotFoundError: No module named 'psycopg2'\n",
            "answer: Issue:\n",
            "e…\n",
            "Solution:\n",
            "pip install psycopg2-binary\n",
            "If you already have it, you might need to update it:\n",
            "pip install psycopg2-binary --upgrade\n",
            "Other methods, if the above fails:\n",
            "if you are getting the “ ModuleNotFoundError: No module named 'psycopg2' “ error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\n",
            "First uninstall the psycopg package\n",
            "Then update conda or pip\n",
            "Then install psycopg again using pip.\n",
            "if you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\n",
            "\n",
            "section: Module 1: Docker and Terraform\n",
            "question: Python - SQLALchemy - TypeError 'module' object is not callable\n",
            "answer: create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \"TypeError: 'module' object is not callable\"\n",
            "Solution:\n",
            "conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
            "engine = create_engine(conn_string)\n",
            "\n",
            "section: Module 6: streaming with kafka\n",
            "question: data-engineering-zoomcamp/week_6_stream_processing/python/resources/rides.csv is missing\n",
            "answer: Copy the file found in the Java example: data-engineering-zoomcamp/week_6_stream_processing/java/kafka_examples/src/main/resources/rides.csv\n",
            "\n",
            "section: Module 1: Docker and Terraform\n",
            "question: WSL - Insufficient system resources exist to complete the requested service.\n",
            "answer: Cause:\n",
            "It happens because the apps are not updated. To be specific, search for any pending updates for Windows Terminal, WSL and Windows Security updates.\n",
            "Solution\n",
            "for updating Windows terminal which worked for me:\n",
            "Go to Microsoft Store.\n",
            "Go to the library of apps installed in your system.\n",
            "Search for Windows terminal.\n",
            "Update the app and restart your system to  see the changes.\n",
            "For updating the Windows security updates:\n",
            "Go to Windows updates and check if there are any pending updates from Windows, especially security updates.\n",
            "Do restart your system once the updates are downloaded and installed successfully.\n",
            "\n",
            "section: Module 1: Docker and Terraform\n",
            "question: Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\n",
            "answer: Error raised during the jupyter notebook’s cell execution:\n",
            "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\n",
            "Solution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\n",
            "</CONTEXT>\n",
            "\n",
            "<PREVIOUS_ACTIONS>\n",
            "{\"action\": \"SEARCH\", \"reasoning\": \"I want to gather specific information about success strategies or tips related to Module 1 to provide the student with relevant advice.\", \"keywords\": [\"success tips Module 1\", \"how to succeed Module 1\", \"Module 1 study strategies\"]}\n",
            "{\"action\": \"SEARCH\", \"reasoning\": \"To provide a more comprehensive response regarding strategies for succeeding in Module 1, I need to find specific tips, techniques, or advice related to this module.\", \"keywords\": [\"Module 1 study tips\", \"how to excel Module 1\", \"Module 1 resources\"]}\n",
            "{\"action\": \"SEARCH\", \"reasoning\": \"I want to explore any additional specific techniques or tips that may help a student improve their chances of success in Module 1, focusing on study habits and effective learning strategies.\", \"keywords\": [\"Module 1 learning strategies\", \"Module 1 success techniques\", \"how to study effectively for Module 1\"]}\n",
            "</PREVIOUS_ACTIONS>\n",
            "{\n",
            "  \"action\": \"ANSWER\",\n",
            "  \"answer\": \"To be successful in Module 1, focus on understanding the core concepts of Docker and Terraform thoroughly. You should follow these practices: \\n1. **Hands-on Practice**: Engage in practical exercises to reinforce your learning. Setting up your own Docker containers and Terraform environments can greatly enhance your understanding. \\n2. **Study Regularly**: Create a study schedule that allows you to review materials consistently instead of cramming before assessments.\\n3. **Utilize Resources**: Make use of all available course materials, such as lecture videos, reading materials, and any additional resources provided within the module. \\n4. **Participate in Discussions**: Engaging with fellow students and instructors in discussion forums can help clarify concepts and expose you to different perspectives.\\n5. **Practice Troubleshooting**: Given the technical nature of the content, it's essential to practice troubleshooting any issues you encounter, such as errors in Docker or Terraform setups. This will help you learn how to resolve problems independently.\\n6. **Seek Help When Needed**: If you're struggling with specific topics, don't hesitate to reach out to your instructors or teaching assistants for assistance. \\n7. **Review Best Practices**: Familiarize yourself with best practices in containerization and infrastructure as code, which will not only help you in assessments but also in real-world applications.\",\n",
            "  \"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Let's put everything together: A multi-step agentic search process to iteratively search, update context, and decide when to stop or answer\n",
        "question = \"what do I need to do to be successful at module 1?\"\n",
        "# Initializes the agent's state: empty search queries, results, and previous actions.\n",
        "search_queries = []\n",
        "search_results = []\n",
        "previous_actions = []\n",
        "\n",
        "\n",
        "iteration = 0\n",
        "# Enters a loop for agentic search\n",
        "while True:\n",
        "    print(f'ITERATION #{iteration}...') # Prints the current iteration\n",
        "\n",
        "    context = build_context(search_results)\n",
        "    prompt = prompt_template.format(\n",
        "        question=question,\n",
        "        context=context,\n",
        "        search_queries=\"\\n\".join(search_queries),\n",
        "        previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
        "        max_iterations=3,\n",
        "        iteration_number=iteration\n",
        "    )\n",
        "\n",
        "    print(prompt)\n",
        "    # Sends the prompt to the LLM, process its response, and update the state for the next iteration\n",
        "    answer_json = llm(prompt)\n",
        "    answer = json.loads(answer_json)\n",
        "    print(json.dumps(answer, indent=2))\n",
        "\n",
        "    previous_actions.append(answer)\n",
        "\n",
        "    action = answer['action']\n",
        "    if action != 'SEARCH':\n",
        "        break\n",
        "\n",
        "    keywords = answer['keywords']\n",
        "    search_queries = list(set(search_queries) | set(keywords))\n",
        "\n",
        "    for k in keywords:\n",
        "        res = search(k)\n",
        "        search_results.extend(res)\n",
        "\n",
        "    search_results = dedup(search_results)\n",
        "\n",
        "    iteration = iteration + 1\n",
        "    if iteration >= 4:\n",
        "        break\n",
        "\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "a2ee162d-15ec-4636-8b6b-8a1265d72ef9",
      "metadata": {
        "id": "a2ee162d-15ec-4636-8b6b-8a1265d72ef9"
      },
      "outputs": [],
      "source": [
        "# Put everything together in a function:\n",
        "def agentic_search(question):\n",
        "    search_queries = []\n",
        "    search_results = []\n",
        "    previous_actions = []\n",
        "\n",
        "    iteration = 0\n",
        "\n",
        "    while True:\n",
        "        print(f'ITERATION #{iteration}...')\n",
        "\n",
        "        context = build_context(search_results)\n",
        "        prompt = prompt_template.format(\n",
        "            question=question,\n",
        "            context=context,\n",
        "            search_queries=\"\\n\".join(search_queries),\n",
        "            previous_actions='\\n'.join([json.dumps(a) for a in previous_actions]),\n",
        "            max_iterations=3,\n",
        "            iteration_number=iteration\n",
        "        )\n",
        "\n",
        "        print(prompt)\n",
        "\n",
        "        answer_json = llm(prompt)\n",
        "        answer = json.loads(answer_json)\n",
        "        print(json.dumps(answer, indent=2))\n",
        "\n",
        "        previous_actions.append(answer)\n",
        "\n",
        "        action = answer['action']\n",
        "        if action != 'SEARCH':\n",
        "            break\n",
        "\n",
        "        keywords = answer['keywords']\n",
        "        search_queries = list(set(search_queries) | set(keywords))\n",
        "\n",
        "        for k in keywords:\n",
        "            res = search(k)\n",
        "            search_results.extend(res)\n",
        "\n",
        "        search_results = dedup(search_results)\n",
        "\n",
        "        iteration = iteration + 1\n",
        "        if iteration >= 4:\n",
        "            break\n",
        "\n",
        "        print()\n",
        "\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "7de2df44-d9fd-4b9c-baa1-ef462c4d8701",
      "metadata": {
        "id": "7de2df44-d9fd-4b9c-baa1-ef462c4d8701",
        "outputId": "9e5c0bbb-cb77-48bc-c091-e129775f95ae",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ITERATION #0...\n",
            "You're a course teaching assistant.\n",
            "\n",
            "You're given a QUESTION from a course student that you need to answer with your own knowledge and provided CONTEXT.\n",
            "\n",
            "The CONTEXT is built with the documents from our FAQ database.\n",
            "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
            "from FAQ to add them to the context.\n",
            "PREVIOUS_ACTIONS contains the actions you already performed.\n",
            "\n",
            "At the beginning the CONTEXT is empty.\n",
            "\n",
            "You can perform the following actions:\n",
            "\n",
            "- Search in the FAQ database to get more data for the CONTEXT\n",
            "- Answer the question using the CONTEXT\n",
            "- Answer the question using your own knowledge\n",
            "\n",
            "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
            "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
            "\n",
            "Don't use search queries used at the previous iterations.\n",
            "\n",
            "\n",
            "Don't repeat previously performed actions.\n",
            "\n",
            "Don't perform more than 3 iterations for a given student question.\n",
            "The current iteration number: 0. If we exceed the allowed number\n",
            "of iterations, give the best possible answer with the provided information.\n",
            "\n",
            "\n",
            "Output templates:\n",
            "\n",
            "If you want to perform search, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"SEARCH\",\n",
            "\"reasoning\": \"<add your reasoning here>\",\n",
            "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
            "}\n",
            "\n",
            "If you can answer the QUESTION using CONTEXT, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER_CONTEXT\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"CONTEXT\"\n",
            "}\n",
            "\n",
            "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n",
            "\n",
            "\n",
            "<QUESTION>\n",
            "how do I prepare for the course?\n",
            "</QUESTION>\n",
            "\n",
            "<SEARCH_QUERIES>\n",
            "\n",
            "</SEARCH_QUERIES>\n",
            "\n",
            "<CONTEXT>\n",
            "\n",
            "</CONTEXT>\n",
            "\n",
            "<PREVIOUS_ACTIONS>\n",
            "\n",
            "</PREVIOUS_ACTIONS>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"action\": \"SEARCH\",\n",
            "  \"reasoning\": \"Since there is no existing context related to preparing for the course, I need to search for relevant FAQs that could provide insights or tips for course preparation.\",\n",
            "  \"keywords\": [\n",
            "    \"course preparation\",\n",
            "    \"how to prepare for a course\",\n",
            "    \"tips for students preparing for a course\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "ITERATION #1...\n",
            "You're a course teaching assistant.\n",
            "\n",
            "You're given a QUESTION from a course student that you need to answer with your own knowledge and provided CONTEXT.\n",
            "\n",
            "The CONTEXT is built with the documents from our FAQ database.\n",
            "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
            "from FAQ to add them to the context.\n",
            "PREVIOUS_ACTIONS contains the actions you already performed.\n",
            "\n",
            "At the beginning the CONTEXT is empty.\n",
            "\n",
            "You can perform the following actions:\n",
            "\n",
            "- Search in the FAQ database to get more data for the CONTEXT\n",
            "- Answer the question using the CONTEXT\n",
            "- Answer the question using your own knowledge\n",
            "\n",
            "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
            "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
            "\n",
            "Don't use search queries used at the previous iterations.\n",
            "\n",
            "\n",
            "Don't repeat previously performed actions.\n",
            "\n",
            "Don't perform more than 3 iterations for a given student question.\n",
            "The current iteration number: 1. If we exceed the allowed number\n",
            "of iterations, give the best possible answer with the provided information.\n",
            "\n",
            "\n",
            "Output templates:\n",
            "\n",
            "If you want to perform search, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"SEARCH\",\n",
            "\"reasoning\": \"<add your reasoning here>\",\n",
            "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
            "}\n",
            "\n",
            "If you can answer the QUESTION using CONTEXT, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER_CONTEXT\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"CONTEXT\"\n",
            "}\n",
            "\n",
            "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n",
            "\n",
            "\n",
            "<QUESTION>\n",
            "how do I prepare for the course?\n",
            "</QUESTION>\n",
            "\n",
            "<SEARCH_QUERIES>\n",
            "course preparation\n",
            "how to prepare for a course\n",
            "tips for students preparing for a course\n",
            "</SEARCH_QUERIES>\n",
            "\n",
            "<CONTEXT>\n",
            "section: General course-related questions\n",
            "question: Course - When will the course start?\n",
            "answer: The purpose of this document is to capture frequently asked technical questions\n",
            "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
            "Subscribe to course public Google Calendar (it works from Desktop only).\n",
            "Register before the course starts using this link.\n",
            "Join the course Telegram channel with announcements.\n",
            "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Course - Can I follow the course after it finishes?\n",
            "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
            "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
            "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
            "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
            "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
            "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
            "\n",
            "section: General course-related questions\n",
            "question: How do I use Git / GitHub for this course?\n",
            "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
            "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
            "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
            "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
            "This is also a great resource: https://dangitgit.com/\n",
            "\n",
            "section: General course-related questions\n",
            "question: Environment - Is the course [Windows/mac/Linux/...] friendly?\n",
            "answer: Yes! Linux is ideal but technically it should not matter. Students last year used all 3 OSes successfully\n",
            "</CONTEXT>\n",
            "\n",
            "<PREVIOUS_ACTIONS>\n",
            "{\"action\": \"SEARCH\", \"reasoning\": \"Since there is no existing context related to preparing for the course, I need to search for relevant FAQs that could provide insights or tips for course preparation.\", \"keywords\": [\"course preparation\", \"how to prepare for a course\", \"tips for students preparing for a course\"]}\n",
            "</PREVIOUS_ACTIONS>\n",
            "{\n",
            "  \"action\": \"SEARCH\",\n",
            "  \"reasoning\": \"Since I have not found specific information on how to prepare for the course yet, I will look for more targeted resources that may provide preparation tips or guidelines for success in the course.\",\n",
            "  \"keywords\": [\n",
            "    \"tips for success in courses\",\n",
            "    \"how to prepare for online courses\",\n",
            "    \"effective study habits for courses\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "ITERATION #2...\n",
            "You're a course teaching assistant.\n",
            "\n",
            "You're given a QUESTION from a course student that you need to answer with your own knowledge and provided CONTEXT.\n",
            "\n",
            "The CONTEXT is built with the documents from our FAQ database.\n",
            "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
            "from FAQ to add them to the context.\n",
            "PREVIOUS_ACTIONS contains the actions you already performed.\n",
            "\n",
            "At the beginning the CONTEXT is empty.\n",
            "\n",
            "You can perform the following actions:\n",
            "\n",
            "- Search in the FAQ database to get more data for the CONTEXT\n",
            "- Answer the question using the CONTEXT\n",
            "- Answer the question using your own knowledge\n",
            "\n",
            "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
            "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
            "\n",
            "Don't use search queries used at the previous iterations.\n",
            "\n",
            "\n",
            "Don't repeat previously performed actions.\n",
            "\n",
            "Don't perform more than 3 iterations for a given student question.\n",
            "The current iteration number: 2. If we exceed the allowed number\n",
            "of iterations, give the best possible answer with the provided information.\n",
            "\n",
            "\n",
            "Output templates:\n",
            "\n",
            "If you want to perform search, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"SEARCH\",\n",
            "\"reasoning\": \"<add your reasoning here>\",\n",
            "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
            "}\n",
            "\n",
            "If you can answer the QUESTION using CONTEXT, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER_CONTEXT\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"CONTEXT\"\n",
            "}\n",
            "\n",
            "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n",
            "\n",
            "\n",
            "<QUESTION>\n",
            "how do I prepare for the course?\n",
            "</QUESTION>\n",
            "\n",
            "<SEARCH_QUERIES>\n",
            "how to prepare for online courses\n",
            "effective study habits for courses\n",
            "tips for success in courses\n",
            "tips for students preparing for a course\n",
            "course preparation\n",
            "how to prepare for a course\n",
            "</SEARCH_QUERIES>\n",
            "\n",
            "<CONTEXT>\n",
            "section: General course-related questions\n",
            "question: Course - When will the course start?\n",
            "answer: The purpose of this document is to capture frequently asked technical questions\n",
            "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
            "Subscribe to course public Google Calendar (it works from Desktop only).\n",
            "Register before the course starts using this link.\n",
            "Join the course Telegram channel with announcements.\n",
            "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Course - Can I follow the course after it finishes?\n",
            "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
            "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
            "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
            "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
            "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
            "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
            "\n",
            "section: General course-related questions\n",
            "question: How do I use Git / GitHub for this course?\n",
            "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
            "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
            "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
            "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
            "This is also a great resource: https://dangitgit.com/\n",
            "\n",
            "section: General course-related questions\n",
            "question: Environment - Is the course [Windows/mac/Linux/...] friendly?\n",
            "answer: Yes! Linux is ideal but technically it should not matter. Students last year used all 3 OSes successfully\n",
            "\n",
            "section: Module 5: pyspark\n",
            "question: Hadoop - Exception in thread \"main\" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\n",
            "answer: If you are seeing this (or similar) error when attempting to write to parquet, it is likely an issue with your path variables.\n",
            "For Windows, create a new User Variable “HADOOP_HOME” that points to your Hadoop directory. Then add “%HADOOP_HOME%\\bin” to the PATH variable.\n",
            "Additional tips can be found here: https://stackoverflow.com/questions/41851066/exception-in-thread-main-java-lang-unsatisfiedlinkerror-org-apache-hadoop-io\n",
            "\n",
            "section: Module 3: Data Warehousing\n",
            "question: GCS Bucket - I query my dataset and get a Bad character (ASCII 0) error?\n",
            "answer: Check the Schema\n",
            "You might have a wrong formatting\n",
            "Try to upload the CSV.GZ files without formatting or going through pandas via wget\n",
            "See this Slack conversation for helpful tips\n",
            "\n",
            "section: General course-related questions\n",
            "question: Leaderboard - I am not on the leaderboard / how do I know which one I am on the leaderboard?\n",
            "answer: When you set up your account you are automatically assigned a random name such as “Lucid Elbakyan” for example. If you want to see what your Display name is.\n",
            "Go to the Homework submission link →  https://courses.datatalks.club/de-zoomcamp-2024/homework/hw2 - Log in > Click on ‘Data Engineering Zoom Camp 2024’ > click on ‘Edit Course Profile’ - your display name is here, you can also change it should you wish:\n",
            "\n",
            "section: General course-related questions\n",
            "question: Course - how many Zoomcamps in a year?\n",
            "answer: There are 3 Zoom Camps in a year, as of 2024. However, they are for separate courses:\n",
            "Data-Engineering (Jan - Apr)\n",
            "MLOps (May - Aug)\n",
            "Machine Learning (Sep - Jan)\n",
            "There's only one Data-Engineering Zoomcamp “live” cohort per year, for the certification. Same as for the other Zoomcamps.\n",
            "They follow pretty much the same schedule for each cohort per zoomcamp. For Data-Engineering it is (generally) from Jan-Apr of the year. If you’re not interested in the Certificate, you can take any zoom camps at any time, at your own pace, out of sync with any “live” cohort.\n",
            "\n",
            "section: Module 1: Docker and Terraform\n",
            "question: Terraform - Error: Failed to query available provider packages │ Could not retrieve the list of available versions for provider hashicorp/google: could not query │ provider registry for registry.terrafogorm.io/hashicorp/google: the request failed after 2 attempts, │ please try again later\n",
            "answer: It is an internet connectivity error, terraform is somehow not able to access the online registry. Check your VPN/Firewall settings (or just clear cookies or restart your network). Try terraform init again after this, it should work.\n",
            "\n",
            "section: Module 2: Workflow Orchestration\n",
            "question: Docker: container crashed with status code 137.\n",
            "answer: It means your container consumed all available RAM allocated to it. It can happen in particular when working on Question#3 in the homework as the dataset is relatively large and containers eat a lot of memory in general.\n",
            "I would recommend restarting your computer and only starting the necessary processes to run the container. If that doesn’t work, allocate more resources to docker. If also that doesn’t work because your workstation is a potato, you can use an online compute environment service like GitPod, which is free under under 50 hours / month of use.\n",
            "</CONTEXT>\n",
            "\n",
            "<PREVIOUS_ACTIONS>\n",
            "{\"action\": \"SEARCH\", \"reasoning\": \"Since there is no existing context related to preparing for the course, I need to search for relevant FAQs that could provide insights or tips for course preparation.\", \"keywords\": [\"course preparation\", \"how to prepare for a course\", \"tips for students preparing for a course\"]}\n",
            "{\"action\": \"SEARCH\", \"reasoning\": \"Since I have not found specific information on how to prepare for the course yet, I will look for more targeted resources that may provide preparation tips or guidelines for success in the course.\", \"keywords\": [\"tips for success in courses\", \"how to prepare for online courses\", \"effective study habits for courses\"]}\n",
            "</PREVIOUS_ACTIONS>\n",
            "{\n",
            "  \"action\": \"SEARCH\",\n",
            "  \"reasoning\": \"Since the previous searches did not yield specific tips or resources for effectively preparing for the course, I will now look for general study strategies and tips that can help students succeed in their coursework.\",\n",
            "  \"keywords\": [\n",
            "    \"study strategies for students\",\n",
            "    \"effective study techniques\",\n",
            "    \"how to succeed in online courses\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "ITERATION #3...\n",
            "You're a course teaching assistant.\n",
            "\n",
            "You're given a QUESTION from a course student that you need to answer with your own knowledge and provided CONTEXT.\n",
            "\n",
            "The CONTEXT is built with the documents from our FAQ database.\n",
            "SEARCH_QUERIES contains the queries that were used to retrieve the documents\n",
            "from FAQ to add them to the context.\n",
            "PREVIOUS_ACTIONS contains the actions you already performed.\n",
            "\n",
            "At the beginning the CONTEXT is empty.\n",
            "\n",
            "You can perform the following actions:\n",
            "\n",
            "- Search in the FAQ database to get more data for the CONTEXT\n",
            "- Answer the question using the CONTEXT\n",
            "- Answer the question using your own knowledge\n",
            "\n",
            "For the SEARCH action, build search requests based on the CONTEXT and the QUESTION.\n",
            "Carefully analyze the CONTEXT and generate the requests to deeply explore the topic.\n",
            "\n",
            "Don't use search queries used at the previous iterations.\n",
            "\n",
            "\n",
            "Don't repeat previously performed actions.\n",
            "\n",
            "Don't perform more than 3 iterations for a given student question.\n",
            "The current iteration number: 3. If we exceed the allowed number\n",
            "of iterations, give the best possible answer with the provided information.\n",
            "\n",
            "\n",
            "Output templates:\n",
            "\n",
            "If you want to perform search, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"SEARCH\",\n",
            "\"reasoning\": \"<add your reasoning here>\",\n",
            "\"keywords\": [\"search query 1\", \"search query 2\", ...]\n",
            "}\n",
            "\n",
            "If you can answer the QUESTION using CONTEXT, use this template:\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER_CONTEXT\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"CONTEXT\"\n",
            "}\n",
            "\n",
            "If the context doesn't contain the answer, use your own knowledge to answer the question\n",
            "\n",
            "{\n",
            "\"action\": \"ANSWER\",\n",
            "\"answer\": \"<your answer>\",\n",
            "\"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n",
            "\n",
            "\n",
            "<QUESTION>\n",
            "how do I prepare for the course?\n",
            "</QUESTION>\n",
            "\n",
            "<SEARCH_QUERIES>\n",
            "study strategies for students\n",
            "effective study habits for courses\n",
            "tips for students preparing for a course\n",
            "course preparation\n",
            "effective study techniques\n",
            "how to succeed in online courses\n",
            "how to prepare for online courses\n",
            "tips for success in courses\n",
            "how to prepare for a course\n",
            "</SEARCH_QUERIES>\n",
            "\n",
            "<CONTEXT>\n",
            "section: General course-related questions\n",
            "question: Course - When will the course start?\n",
            "answer: The purpose of this document is to capture frequently asked technical questions\n",
            "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
            "Subscribe to course public Google Calendar (it works from Desktop only).\n",
            "Register before the course starts using this link.\n",
            "Join the course Telegram channel with announcements.\n",
            "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Course - Can I follow the course after it finishes?\n",
            "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
            "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Certificate - Can I follow the course in a self-paced mode and get a certificate?\n",
            "answer: No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Is it possible to use tool “X” instead of the one tool you use in the course?\n",
            "answer: Yes, this applies if you want to use Airflow or Prefect instead of Mage, AWS or Snowflake instead of GCP products or Tableau instead of Metabase or Google data studio.\n",
            "The course covers 2 alternative data stacks, one using GCP and one using local installation of everything. You can use one of them or use your tool of choice.\n",
            "Should you consider it instead of the one tool you use? That we can’t support you if you choose to use a different stack, also you would need to explain the different choices of tool for the peer review of your capstone project.\n",
            "\n",
            "section: General course-related questions\n",
            "question: How do I use Git / GitHub for this course?\n",
            "answer: After you create a GitHub account, you should clone the course repo to your local machine using the process outlined in this video: Git for Everybody: How to Clone a Repository from GitHub\n",
            "Having this local repository on your computer will make it easy for you to access the instructors’ code and make pull requests (if you want to add your own notes or make changes to the course content).\n",
            "You will probably also create your own repositories that host your notes, versions of your file, to do this. Here is a great tutorial that shows you how to do this: https://www.atlassian.com/git/tutorials/setting-up-a-repository\n",
            "Remember to ignore large database, .csv, and .gz files, and other files that should not be saved to a repository. Use .gitignore for this: https://www.atlassian.com/git/tutorials/saving-changes/gitignore NEVER store passwords or keys in a git repo (even if that repo is set to private).\n",
            "This is also a great resource: https://dangitgit.com/\n",
            "\n",
            "section: General course-related questions\n",
            "question: Environment - Is the course [Windows/mac/Linux/...] friendly?\n",
            "answer: Yes! Linux is ideal but technically it should not matter. Students last year used all 3 OSes successfully\n",
            "\n",
            "section: Module 5: pyspark\n",
            "question: Hadoop - Exception in thread \"main\" java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z\n",
            "answer: If you are seeing this (or similar) error when attempting to write to parquet, it is likely an issue with your path variables.\n",
            "For Windows, create a new User Variable “HADOOP_HOME” that points to your Hadoop directory. Then add “%HADOOP_HOME%\\bin” to the PATH variable.\n",
            "Additional tips can be found here: https://stackoverflow.com/questions/41851066/exception-in-thread-main-java-lang-unsatisfiedlinkerror-org-apache-hadoop-io\n",
            "\n",
            "section: Module 3: Data Warehousing\n",
            "question: GCS Bucket - I query my dataset and get a Bad character (ASCII 0) error?\n",
            "answer: Check the Schema\n",
            "You might have a wrong formatting\n",
            "Try to upload the CSV.GZ files without formatting or going through pandas via wget\n",
            "See this Slack conversation for helpful tips\n",
            "\n",
            "section: General course-related questions\n",
            "question: Leaderboard - I am not on the leaderboard / how do I know which one I am on the leaderboard?\n",
            "answer: When you set up your account you are automatically assigned a random name such as “Lucid Elbakyan” for example. If you want to see what your Display name is.\n",
            "Go to the Homework submission link →  https://courses.datatalks.club/de-zoomcamp-2024/homework/hw2 - Log in > Click on ‘Data Engineering Zoom Camp 2024’ > click on ‘Edit Course Profile’ - your display name is here, you can also change it should you wish:\n",
            "\n",
            "section: General course-related questions\n",
            "question: Course - how many Zoomcamps in a year?\n",
            "answer: There are 3 Zoom Camps in a year, as of 2024. However, they are for separate courses:\n",
            "Data-Engineering (Jan - Apr)\n",
            "MLOps (May - Aug)\n",
            "Machine Learning (Sep - Jan)\n",
            "There's only one Data-Engineering Zoomcamp “live” cohort per year, for the certification. Same as for the other Zoomcamps.\n",
            "They follow pretty much the same schedule for each cohort per zoomcamp. For Data-Engineering it is (generally) from Jan-Apr of the year. If you’re not interested in the Certificate, you can take any zoom camps at any time, at your own pace, out of sync with any “live” cohort.\n",
            "\n",
            "section: Module 1: Docker and Terraform\n",
            "question: Terraform - Error: Failed to query available provider packages │ Could not retrieve the list of available versions for provider hashicorp/google: could not query │ provider registry for registry.terrafogorm.io/hashicorp/google: the request failed after 2 attempts, │ please try again later\n",
            "answer: It is an internet connectivity error, terraform is somehow not able to access the online registry. Check your VPN/Firewall settings (or just clear cookies or restart your network). Try terraform init again after this, it should work.\n",
            "\n",
            "section: Module 2: Workflow Orchestration\n",
            "question: Docker: container crashed with status code 137.\n",
            "answer: It means your container consumed all available RAM allocated to it. It can happen in particular when working on Question#3 in the homework as the dataset is relatively large and containers eat a lot of memory in general.\n",
            "I would recommend restarting your computer and only starting the necessary processes to run the container. If that doesn’t work, allocate more resources to docker. If also that doesn’t work because your workstation is a potato, you can use an online compute environment service like GitPod, which is free under under 50 hours / month of use.\n",
            "\n",
            "section: General course-related questions\n",
            "question: Office Hours - What is the video/zoom link to the stream for the “Office Hour” or workshop sessions?\n",
            "answer: The zoom link is only published to instructors/presenters/TAs.\n",
            "Students participate via Youtube Live and submit questions to Slido (link would be pinned in the chat when Alexey goes Live). The video URL should be posted in the announcements channel on Telegram & Slack before it begins. Also, you will see it live on the DataTalksClub YouTube Channel.\n",
            "Don’t post your questions in chat as it would be off-screen before the instructors/moderators have a chance to answer it if the room is very active.\n",
            "\n",
            "section: General course-related questions\n",
            "question: How to troubleshoot issues\n",
            "answer: The first step is to try to solve the issue on your own. Get used to solving problems and reading documentation. This will be a real life skill you need when employed. [ctrl+f] is your friend, use it! It is a universal shortcut and works in all apps/browsers.\n",
            "What does the error say? There will often be a description of the error or instructions on what is needed or even how to fix it. I have even seen a link to the solution. Does it reference a specific line of your code?\n",
            "Restart app or server/pc.\n",
            "Google it, use ChatGPT, Bing AI etc.\n",
            "It is going to be rare that you are the first to have the problem, someone out there has posted the fly issue and likely the solution.\n",
            "Search using: <technology> <problem statement>. Example: pgcli error column c.relhasoids does not exist.\n",
            "There are often different solutions for the same problem due to variation in environments.\n",
            "Check the tech’s documentation. Use its search if available or use the browsers search function.\n",
            "Try uninstall (this may remove the bad actor) and reinstall of application or reimplementation of action. Remember to restart the server/pc for reinstalls.\n",
            "Sometimes reinstalling fails to resolve the issue but works if you uninstall first.\n",
            "Post your question to Stackoverflow. Read the Stackoverflow guide on posting good questions.\n",
            "https://stackoverflow.com/help/how-to-ask\n",
            "This will be your real life. Ask an expert in the future (in addition to coworkers).\n",
            "Ask in Slack\n",
            "Before asking a question,\n",
            "Check Pins (where the shortcut to the repo and this FAQ is located)\n",
            "Use the slack app’s search function\n",
            "Use the bot @ZoomcampQABot to do the search for you\n",
            "check the FAQ (this document), use search [ctrl+f]\n",
            "When asking a question, include as much information as possible:\n",
            "What are you coding on? What OS?\n",
            "What command did you run, which video did you follow? Etc etc\n",
            "What error did you get? Does it have a line number to the “offending” code and have you check it for typos?\n",
            "What have you tried that did not work? This answer is crucial as without it, helpers would ask you to do the suggestions in the error log first. Or just read this FAQ document.\n",
            "DO NOT use screenshots, especially don’t take pictures from a phone.\n",
            "DO NOT tag instructors, it may discourage others from helping you. Copy and paste errors; if it’s long, just post it in a reply to your thread.\n",
            "Use ``` for formatting your code.\n",
            "Use the same thread for the conversation (that means reply to your own thread).\n",
            "DO NOT create multiple posts to discuss the issue.\n",
            "learYou may create a new post if the issue reemerges down the road. Describe what has changed in the environment.\n",
            "Provide additional information in the same thread of the steps you have taken for resolution.\n",
            "Take a break and come back later. You will be amazed at how often you figure out the solution after letting your brain rest. Get some fresh air, workout, play a video game, watch a tv show, whatever allows your brain to not think about it for a little while or even until the next day.\n",
            "Remember technology issues in real life sometimes take days or even weeks to resolve.\n",
            "If somebody helped you with your problem and it's not in the FAQ, please add it there. It will help other students.\n",
            "\n",
            "section: Module 1: Docker and Terraform\n",
            "question: GCP VM - Is it necessary to use a GCP VM? When is it useful?\n",
            "answer: The reason this video about the GCP VM exists is that many students had problems configuring their env. You can use your own env if it works for you.\n",
            "And the advantage of using your own environment is that if you are working in a Github repo where you can commit, you will be able to commit the changes that you do. In the VM the repo is cloned via HTTPS so it is not possible to directly commit, even if you are the owner of the repo.\n",
            "\n",
            "section: Project\n",
            "question: How is my capstone project going to be evaluated?\n",
            "answer: Each submitted project will be evaluated by 3 (three) randomly assigned students that have also submitted the project.\n",
            "You will also be responsible for grading the projects from 3 fellow students yourself. Please be aware that: not complying to this rule also implies you failing to achieve the Certificate at the end of the course.\n",
            "The final grade you get will be the median score of the grades you get from the peer reviewers.\n",
            "And of course, the peer review criteria for evaluating or being evaluated must follow the guidelines defined here.\n",
            "</CONTEXT>\n",
            "\n",
            "<PREVIOUS_ACTIONS>\n",
            "{\"action\": \"SEARCH\", \"reasoning\": \"Since there is no existing context related to preparing for the course, I need to search for relevant FAQs that could provide insights or tips for course preparation.\", \"keywords\": [\"course preparation\", \"how to prepare for a course\", \"tips for students preparing for a course\"]}\n",
            "{\"action\": \"SEARCH\", \"reasoning\": \"Since I have not found specific information on how to prepare for the course yet, I will look for more targeted resources that may provide preparation tips or guidelines for success in the course.\", \"keywords\": [\"tips for success in courses\", \"how to prepare for online courses\", \"effective study habits for courses\"]}\n",
            "{\"action\": \"SEARCH\", \"reasoning\": \"Since the previous searches did not yield specific tips or resources for effectively preparing for the course, I will now look for general study strategies and tips that can help students succeed in their coursework.\", \"keywords\": [\"study strategies for students\", \"effective study techniques\", \"how to succeed in online courses\"]}\n",
            "</PREVIOUS_ACTIONS>\n",
            "{\n",
            "  \"action\": \"ANSWER\",\n",
            "  \"answer\": \"To prepare for the course effectively, here are some strategies: \\n1. **Familiarize Yourself with the Course Materials**: Review any provided syllabus, readings, and resources in advance.\\n2. **Set Up Your Environment**: If the course involves technical components, ensure you have all the necessary tools and software installed.\\n3. **Plan Your Schedule**: Allocate specific times for studying and attending live sessions. \\n4. **Engage with Peers and Instructors**: Join the course-related communication platforms like Slack and Telegram to connect with fellow students and ask questions.\\n5. **Practice Active Learning**: Engage with the content through discussions, exercises, and practical applications to reinforce your understanding.\\n6. **Stay Organized**: Use calendars or planners to keep track of important dates and deadlines.\\n7. **Set Goals**: Define what you hope to achieve in the course and track your progress.\\n8. **Seek Additional Resources**: Look for supplementary materials or online resources that can enhance your understanding of the course topics.\\nBy implementing these strategies, you will be better positioned to succeed in your course.\",\n",
            "  \"source\": \"OWN_KNOWLEDGE\"\n",
            "}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'action': 'ANSWER',\n",
              " 'answer': 'To prepare for the course effectively, here are some strategies: \\n1. **Familiarize Yourself with the Course Materials**: Review any provided syllabus, readings, and resources in advance.\\n2. **Set Up Your Environment**: If the course involves technical components, ensure you have all the necessary tools and software installed.\\n3. **Plan Your Schedule**: Allocate specific times for studying and attending live sessions. \\n4. **Engage with Peers and Instructors**: Join the course-related communication platforms like Slack and Telegram to connect with fellow students and ask questions.\\n5. **Practice Active Learning**: Engage with the content through discussions, exercises, and practical applications to reinforce your understanding.\\n6. **Stay Organized**: Use calendars or planners to keep track of important dates and deadlines.\\n7. **Set Goals**: Define what you hope to achieve in the course and track your progress.\\n8. **Seek Additional Resources**: Look for supplementary materials or online resources that can enhance your understanding of the course topics.\\nBy implementing these strategies, you will be better positioned to succeed in your course.',\n",
              " 'source': 'OWN_KNOWLEDGE'}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test it:\n",
        "agentic_search('how do I prepare for the course?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "66788038-148f-4da1-adfe-22de6e1773c5",
      "metadata": {
        "id": "66788038-148f-4da1-adfe-22de6e1773c5",
        "outputId": "c53e7860-aaa2-4dce-97ca-c2cc2719e872"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To prepare for the course effectively, here are some strategies: \n",
            "1. **Familiarize Yourself with the Course Materials**: Review any provided syllabus, readings, and resources in advance.\n",
            "2. **Set Up Your Environment**: If the course involves technical components, ensure you have all the necessary tools and software installed.\n",
            "3. **Plan Your Schedule**: Allocate specific times for studying and attending live sessions. \n",
            "4. **Engage with Peers and Instructors**: Join the course-related communication platforms like Slack and Telegram to connect with fellow students and ask questions.\n",
            "5. **Practice Active Learning**: Engage with the content through discussions, exercises, and practical applications to reinforce your understanding.\n",
            "6. **Stay Organized**: Use calendars or planners to keep track of important dates and deadlines.\n",
            "7. **Set Goals**: Define what you hope to achieve in the course and track your progress.\n",
            "8. **Seek Additional Resources**: Look for supplementary materials or online resources that can enhance your understanding of the course topics.\n",
            "By implementing these strategies, you will be better positioned to succeed in your course.\n"
          ]
        }
      ],
      "source": [
        "print(_['answer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4353d1d5-d7c9-4f27-b12e-3dc51d27be85",
      "metadata": {
        "id": "4353d1d5-d7c9-4f27-b12e-3dc51d27be85"
      },
      "source": [
        "# Part 3: Function calling\n",
        "\n",
        "Function calling in OpenAI\n",
        "We put all this logic inside our prompt.\n",
        "\n",
        "But OpenAI and other providers provide a convenient API for adding extra functionality like search.\n",
        "\n",
        "* https://platform.openai.com/docs/guides/function-calling\n",
        "\n",
        "It's called \"function calling\" - you define functions that the model can call, and if it decides to make a call, it returns structured output for that.\n",
        "\n",
        "For example, let's take our search function:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "yHBVVgBE_K5A",
      "metadata": {
        "id": "yHBVVgBE_K5A"
      },
      "outputs": [],
      "source": [
        "def search(query):\n",
        "    boost = {'question': 3.0, 'section': 0.5}\n",
        "\n",
        "    results = index.search(\n",
        "        query=query,\n",
        "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
        "        boost_dict=boost,\n",
        "        num_results=5,\n",
        "        output_ids=True\n",
        "    )\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "28133938-0af4-4e9d-825f-4f44d42b5484",
      "metadata": {
        "id": "28133938-0af4-4e9d-825f-4f44d42b5484"
      },
      "outputs": [],
      "source": [
        "# We describe it like that:\n",
        "search_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"search\",\n",
        "    \"description\": \"Search the FAQ database\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"query\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Search query text to look up in the course FAQ.\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"query\"],\n",
        "        \"additionalProperties\": False\n",
        "    }\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jUraMucz_fOS",
      "metadata": {
        "id": "jUraMucz_fOS"
      },
      "source": [
        "Here we have:\n",
        "\n",
        "* name: search\n",
        "* description: when to use it\n",
        "* parameters: all the arguments that the function can take and their description\n",
        "\n",
        "In order to use function calling, we'll use a newer API - the \"responses\" API (not \"chat completions\" as previously):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "df28b463-990a-482d-ba49-c55403bbf2f1",
      "metadata": {
        "id": "df28b463-990a-482d-ba49-c55403bbf2f1"
      },
      "outputs": [],
      "source": [
        "tools = [search_tool]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "c0ac6e7d-bbc1-40fd-8b34-249f9805f3d7",
      "metadata": {
        "id": "c0ac6e7d-bbc1-40fd-8b34-249f9805f3d7"
      },
      "outputs": [],
      "source": [
        "question = \"How do I do well in module 1?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "c48fb94b-5a14-4d7c-a695-f9672c846ed0",
      "metadata": {
        "id": "c48fb94b-5a14-4d7c-a695-f9672c846ed0"
      },
      "outputs": [],
      "source": [
        "developer_prompt = \"\"\"\n",
        "You're a course teaching assistant.\n",
        "You're given a question from a course student and your task is to answer it.\n",
        "\"\"\".strip()\n",
        "\n",
        "chat_messages = [\n",
        "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
        "    {\"role\": \"user\", \"content\": question}\n",
        "]\n",
        "\n",
        "response = client.responses.create( # the \"responses\" API\n",
        "    model='gpt-4o-mini',\n",
        "    input=chat_messages,\n",
        "    tools=tools\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "81502be5-0e65-4364-8c64-9dee771f5a4a",
      "metadata": {
        "id": "81502be5-0e65-4364-8c64-9dee771f5a4a",
        "outputId": "4c786dfb-eee3-4d50-e776-09188629b552"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Response(id='resp_689452dc54d081a3a8520ad5544eb3a80df1a2059b15a18a', created_at=1754551004.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseFunctionToolCall(arguments='{\"query\":\"do well in module 1\"}', call_id='call_mS8OiMYJGN2v8aY6luKWXEAY', name='search', type='function_call', id='fc_689452dd708c81a3af4333b24a3338ac0df1a2059b15a18a', status='completed')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[FunctionTool(name='search', parameters={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query text to look up in the course FAQ.'}}, 'required': ['query'], 'additionalProperties': False}, strict=True, type='function', description='Search the FAQ database')], top_p=1.0, background=False, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=83, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=19, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=102), user=None, max_tool_calls=None, prompt_cache_key=None, safety_identifier=None, store=True, top_logprobs=0)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "781242a3-c3b0-4083-9adc-d88aa8797885",
      "metadata": {
        "id": "781242a3-c3b0-4083-9adc-d88aa8797885",
        "outputId": "cf0df0ce-e62a-4d9a-fde6-5bbde95641ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[ResponseFunctionToolCall(arguments='{\"query\":\"do well in module 1\"}', call_id='call_mS8OiMYJGN2v8aY6luKWXEAY', name='search', type='function_call', id='fc_689452dd708c81a3af4333b24a3338ac0df1a2059b15a18a', status='completed')]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# If the model thinks we should make a function call, it will tell us:\n",
        "response.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "a8c5723a-cbf4-4e71-a07b-73ca4016c3c8",
      "metadata": {
        "id": "a8c5723a-cbf4-4e71-a07b-73ca4016c3c8"
      },
      "outputs": [],
      "source": [
        "# Let's make a call to search:\n",
        "# response.choices[0].message.content\n",
        "calls = response.output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "7759e3c4-835a-4fee-9f15-30b19706ace8",
      "metadata": {
        "id": "7759e3c4-835a-4fee-9f15-30b19706ace8",
        "outputId": "2830b9cc-8117-4713-930e-0c3a8110b273"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResponseFunctionToolCall(arguments='{\"query\":\"do well in module 1\"}', call_id='call_mS8OiMYJGN2v8aY6luKWXEAY', name='search', type='function_call', id='fc_689452dd708c81a3af4333b24a3338ac0df1a2059b15a18a', status='completed')"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "call = calls[0]\n",
        "call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "e14a75d1-981e-44f7-bc2b-bf24509d11f5",
      "metadata": {
        "id": "e14a75d1-981e-44f7-bc2b-bf24509d11f5",
        "outputId": "bceb3645-a6ac-470b-821b-37cfabe9c752"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'call_mS8OiMYJGN2v8aY6luKWXEAY'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "call.call_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "4226a3ff-4cd0-4e2f-9c22-96c7a035ba4e",
      "metadata": {
        "id": "4226a3ff-4cd0-4e2f-9c22-96c7a035ba4e",
        "outputId": "52236dc6-6b26-4ce6-8696-f45c1e7b5ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'search'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f_name = call.name\n",
        "f_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "c6fb3740-089f-4c26-a3bc-87dbc9e145c2",
      "metadata": {
        "id": "c6fb3740-089f-4c26-a3bc-87dbc9e145c2",
        "outputId": "ba5bc1f7-8464-4d19-8363-a59ef44ca58e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'query': 'do well in module 1'}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arguments = json.loads(call.arguments)\n",
        "arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "11d47c39-2688-432a-afc8-b7d481487123",
      "metadata": {
        "id": "11d47c39-2688-432a-afc8-b7d481487123"
      },
      "outputs": [],
      "source": [
        "# Using f_name we can find the function we need:\n",
        "f = globals()[f_name] # f is a reference to the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "ac44a26e-f5b3-4e7f-997a-ba709d0bef98",
      "metadata": {
        "id": "ac44a26e-f5b3-4e7f-997a-ba709d0bef98"
      },
      "outputs": [],
      "source": [
        "# And invoke it with the arguments:\n",
        "results = f(**arguments) # Unpack dictionary into keyword arguments: f(query=\"module 1 success tips\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "81342abc-e9f3-4fa5-a546-fd317c292b14",
      "metadata": {
        "id": "81342abc-e9f3-4fa5-a546-fd317c292b14",
        "outputId": "21cfc1ce-40ac-4d0a-95ed-46b0c0e09696",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\\\"Murray Hill\\\") & (new_final.b_zone==\\\"Midwood\\\")).show()\\nKrishna Anand\",\n",
            "    \"section\": \"Module 5: pyspark\",\n",
            "    \"question\": \"Module Not Found Error in Jupyter Notebook .\",\n",
            "    \"course\": \"data-engineering-zoomcamp\",\n",
            "    \"_id\": 322\n",
            "  },\n",
            "  {\n",
            "    \"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\u201d\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\"` appropriately.\\nAdditionally, you can check for the version of \\u2018py4j\\u2019 of the spark you\\u2019re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\",\n",
            "    \"section\": \"Module 5: pyspark\",\n",
            "    \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
            "    \"course\": \"data-engineering-zoomcamp\",\n",
            "    \"_id\": 323\n",
            "  },\n",
            "  {\n",
            "    \"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
            "    \"section\": \"Module 4: analytics engineering with dbt\",\n",
            "    \"question\": \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
            "    \"course\": \"data-engineering-zoomcamp\",\n",
            "    \"_id\": 299\n",
            "  },\n",
            "  {\n",
            "    \"text\": \"create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \\\"TypeError: 'module' object is not callable\\\"\\nSolution:\\nconn_string = \\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\"\\nengine = create_engine(conn_string)\",\n",
            "    \"section\": \"Module 1: Docker and Terraform\",\n",
            "    \"question\": \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
            "    \"course\": \"data-engineering-zoomcamp\",\n",
            "    \"_id\": 124\n",
            "  },\n",
            "  {\n",
            "    \"text\": \"Error raised during the jupyter notebook\\u2019s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module \\u201cpsycopg2\\u201d. Can be installed by Conda or pip.\",\n",
            "    \"section\": \"Module 1: Docker and Terraform\",\n",
            "    \"question\": \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\",\n",
            "    \"course\": \"data-engineering-zoomcamp\",\n",
            "    \"_id\": 125\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# Now let's save the results as json:\n",
        "search_results = json.dumps(results, indent=2)\n",
        "# search_results contains FAQ entries from the course database that match a search query:\n",
        "print(search_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "572bc1e3-51b0-4dc1-9030-131a9a057c53",
      "metadata": {
        "id": "572bc1e3-51b0-4dc1-9030-131a9a057c53"
      },
      "outputs": [],
      "source": [
        "# And save both the response and the result of the function call:\n",
        "chat_messages.append(call) # keep a record of the model's tool usage for context in future API calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "f1099da2-9710-4d24-865f-9d59ecfc9e37",
      "metadata": {
        "id": "f1099da2-9710-4d24-865f-9d59ecfc9e37"
      },
      "outputs": [],
      "source": [
        "# chat_messages.append(call) saves the function call request (what the model wanted to do).\n",
        "# The current cell saves the function call output (the actual result/data returned by the function)\n",
        "chat_messages.append({\n",
        "    \"type\": \"function_call_output\",\n",
        "    \"call_id\": call.call_id,\n",
        "    \"output\": search_results,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "7b41e545-626f-471c-b9a7-4d74efc2f96e",
      "metadata": {
        "id": "7b41e545-626f-471c-b9a7-4d74efc2f96e"
      },
      "outputs": [],
      "source": [
        "# Now chat_messages contains both the call description (so it keeps track of history) and the results\n",
        "# Let's make another call to the model:\n",
        "response = client.responses.create(\n",
        "    model='gpt-4o-mini',\n",
        "    input=chat_messages,\n",
        "    tools=tools\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "5576052f-7244-4b3c-ac18-3e3d305739dd",
      "metadata": {
        "id": "5576052f-7244-4b3c-ac18-3e3d305739dd"
      },
      "outputs": [],
      "source": [
        "# This should be the response (a final answer but can also be another call if it needs more information):\n",
        "r = response.output[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "d91eb0af-cf09-410e-93ca-407aebf551b1",
      "metadata": {
        "id": "d91eb0af-cf09-410e-93ca-407aebf551b1",
        "outputId": "fba48435-cc44-4d0a-e777-68ac61c299ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To do well in Module 1 of your course, here are some key tips:\n",
            "\n",
            "1. **Understand the Basics**: Make sure you have a strong grasp of Docker and Terraform concepts covered in this module. Familiarize yourself with how these technologies work and their purposes.\n",
            "\n",
            "2. **Follow Instructions**: Carefully follow all installation and setup instructions provided. Ensure all dependencies are correctly installed, including Docker and the necessary Python packages (like `psycopg2`).\n",
            "\n",
            "3. **Practice Coding**: Engage in hands-on coding. Experiment with creating Docker images and using Terraform for infrastructure deployment.\n",
            "\n",
            "4. **Resolve Errors Promptly**: If you encounter errors, such as `ModuleNotFoundError` or others, troubleshoot them immediately. For instance:\n",
            "   - If facing a `ModuleNotFoundError` like for `psycopg2`, ensure it's installed via pip or conda.\n",
            "   - If an error arises with SQLAlchemy, double-check your connection strings.\n",
            "\n",
            "5. **Leverage Resources**: Utilize course materials, documentation, and forums for additional support. Don't hesitate to seek help if you're stuck.\n",
            "\n",
            "6. **Regular Reviews**: Revisit the material regularly to reinforce your understanding.\n",
            "\n",
            "7. **Engage with Peers**: Collaborate with fellow students. Discussing concepts and problems can enhance learning.\n",
            "\n",
            "By following these steps, you'll be better positioned to succeed in Module 1!\n"
          ]
        }
      ],
      "source": [
        "print(r.content[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "e6195a9d-f737-415e-bfb5-a413d449c94a",
      "metadata": {
        "id": "e6195a9d-f737-415e-bfb5-a413d449c94a",
        "outputId": "ea064df1-f4f3-462a-c80c-f7865578fb65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'message'"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r.type # 'message' represents a standard text response from the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "1ee391d2-8b2a-4b8c-85f7-6a56d5fa3f82",
      "metadata": {
        "id": "1ee391d2-8b2a-4b8c-85f7-6a56d5fa3f82",
        "outputId": "a0322670-2a53-40b1-f21d-e61e445df405"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'function_call'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "call.type # 'function_call' represents a  request from the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec5746ea-4d80-4eee-8d16-95305cc66ebc",
      "metadata": {
        "id": "ec5746ea-4d80-4eee-8d16-95305cc66ebc"
      },
      "source": [
        "## Making multiple calls\n",
        "What if we want to make multiple calls? Change the developer prompt a little:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "f5567651-5716-4d47-9002-d347bd69b7db",
      "metadata": {
        "id": "f5567651-5716-4d47-9002-d347bd69b7db"
      },
      "outputs": [],
      "source": [
        "developer_prompt = \"\"\"\n",
        "You're a course teaching assistant.\n",
        "You're given a question from a course student and your task is to answer it.\n",
        "If you look up something in FAQ, convert the student question into multiple queries.\n",
        "\"\"\".strip()\n",
        "\n",
        "chat_messages = [\n",
        "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
        "    {\"role\": \"user\", \"content\": question}\n",
        "]\n",
        "\n",
        "response = client.responses.create(\n",
        "    model='gpt-4o-mini',\n",
        "    input=chat_messages,\n",
        "    tools=tools\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "fd69ffd0-2a4b-454e-87bd-2ff976d61a43",
      "metadata": {
        "id": "fd69ffd0-2a4b-454e-87bd-2ff976d61a43"
      },
      "outputs": [],
      "source": [
        "# Let's organize our code a little. First, create a function do_call:\n",
        "def do_call(tool_call_response):\n",
        "    function_name = tool_call_response.name # The name of the function to call\n",
        "    arguments = json.loads(tool_call_response.arguments) # Parses the arguments from JSON\n",
        "\n",
        "    f = globals()[function_name] # Finds the function in the global namespace\n",
        "    result = f(**arguments)\n",
        "\n",
        "    return {\n",
        "        \"type\": \"function_call_output\",\n",
        "        \"call_id\": tool_call_response.call_id, # \"call_id\" (to link output to the original call)\n",
        "        \"output\": json.dumps(result, indent=2),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "ac9a762c-1836-4573-b0e5-c927e2fb47b3",
      "metadata": {
        "id": "ac9a762c-1836-4573-b0e5-c927e2fb47b3",
        "outputId": "864d3519-4bf4-4a1c-ad79-81169b5ba082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "function_call\n",
            "function_call\n",
            "function_call\n"
          ]
        }
      ],
      "source": [
        "# Now iterate over responses:\n",
        "for entry in response.output:\n",
        "    chat_messages.append(entry)\n",
        "    print(entry.type)\n",
        "\n",
        "    if entry.type == 'function_call':\n",
        "        result = do_call(entry)\n",
        "        chat_messages.append(result)\n",
        "    elif entry.type == 'message':\n",
        "        print(entry.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "caee8500-ffc9-4aa8-9f88-283f3a5d9446",
      "metadata": {
        "id": "caee8500-ffc9-4aa8-9f88-283f3a5d9446",
        "outputId": "af228eb7-4bde-45fd-f248-7f48b03b6cac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "message\n",
            "\n",
            "To excel in Module 1 of your course, here are some key strategies and tips:\n",
            "\n",
            "### Understanding the Content:\n",
            "1. **Familiarize with Docker and Terraform:** Ensure you have a solid grasp of the basics of both Docker and Terraform, as these technologies are essential for the module. \n",
            "2. **Hands-On Practice:** Set up local environments using Docker containers to apply what you've learned in theory.\n",
            "\n",
            "### Addressing Common Issues:\n",
            "1. **Dependencies:** If you encounter issues like `ModuleNotFoundError` for libraries such as `psycopg2`, make sure to install the required packages:\n",
            "   - Use: `pip install psycopg2-binary`\n",
            "   - If you face further issues, try upgrading the package: `pip install psycopg2-binary --upgrade`.\n",
            "\n",
            "2. **Connection Strings:** When creating SQLAlchemy engines, ensure your connection strings are accurate:\n",
            "   - Example: \n",
            "   ```python\n",
            "   conn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\n",
            "   engine = create_engine(conn_string)\n",
            "   ```\n",
            "\n",
            "### General Study Tips:\n",
            "- **Follow Tutorials Closely:** Pay attention to the specifics in setup instructions, especially around using Docker.\n",
            "- **Use Forums and FAQs:** Engage with course forums and refer to the FAQ sections to get insights from fellow learners and tutors.\n",
            "\n",
            "### Additional Resources:\n",
            "- **Locate Key Files:** Familiarize yourself with file structures and versioning, especially for dependencies like `py4j` and `psycopg2`.\n",
            "- **Experiment with Examples:** Run provided examples and tweak them to see how they behave, enhancing your learning experience through experimentation.\n",
            "\n",
            "By consistently applying these strategies, you’ll improve your understanding and performance in Module 1. If you have specific concerns or need further information on any point, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "# First call will probably be function call, so let's do another one (This one is a text response)\n",
        "# After updating the conversation history, next API call will likely be a regular text answer:\n",
        "response = client.responses.create(\n",
        "    model='gpt-4o-mini',\n",
        "    input=chat_messages,\n",
        "    tools=tools\n",
        ")\n",
        "\n",
        "for entry in response.output:\n",
        "    chat_messages.append(entry)\n",
        "    print(entry.type)\n",
        "    print()\n",
        "\n",
        "    if entry.type == 'function_call':\n",
        "        result = do_call(entry)\n",
        "        chat_messages.append(result)\n",
        "    elif entry.type == 'message':\n",
        "        print(entry.content[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f52fc54b-10a1-4aa8-88e5-dab893e612ee",
      "metadata": {
        "id": "f52fc54b-10a1-4aa8-88e5-dab893e612ee"
      },
      "source": [
        "## Putting it all together"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "722923e7-9fe3-4561-bf3f-682de839a6ac",
      "metadata": {
        "id": "722923e7-9fe3-4561-bf3f-682de839a6ac"
      },
      "source": [
        "Above was a text response. But what if it's not? Use two loops:\n",
        "\n",
        "- First is the main Q&A loop - ask question, get back the answer\n",
        "- Second is the request-response loop - send requests until there's a message reply from API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "87be0bfd-7fd8-4102-b05d-f6ef4fd48fde",
      "metadata": {
        "id": "87be0bfd-7fd8-4102-b05d-f6ef4fd48fde"
      },
      "outputs": [],
      "source": [
        "developer_prompt = \"\"\"\n",
        "You're a course teaching assistant.\n",
        "You're given a question from a course student and your task is to answer it.\n",
        "\n",
        "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
        "When using FAQ, perform deep topic exploration: make one request to FAQ,\n",
        "and then based on the results, make more requests.\n",
        "\n",
        "At the end of each response, ask the user a follow up question based on your answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "chat_messages = [\n",
        "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30e23311",
      "metadata": {},
      "source": [
        "After running the next cell, type your question when prompted. Type 'stop' to exit the chat loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "9615aa6a-4103-4e04-b327-f2009d8214bc",
      "metadata": {
        "id": "9615aa6a-4103-4e04-b327-f2009d8214bc",
        "outputId": "e3863f8c-ad96-4e9b-f6ca-6ae9df6d680e",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "function_call: ResponseFunctionToolCall(arguments='{\"query\":\"best practices for module 1\"}', call_id='call_S34plQTcdDqakLEuBLS8d2Pw', name='search', type='function_call', id='fc_68945315cee881a090ca0d2395c1994c08c1c7312e6e0cae', status='completed')\n",
            "\n",
            "function_call: ResponseFunctionToolCall(arguments='{\"query\":\"module 1 Docker Terraform tips\"}', call_id='call_Dwty4vYTSwKPQvggIgoXG1BN', name='search', type='function_call', id='fc_68945317497c81a0807c5e387bb12dc508c1c7312e6e0cae', status='completed')\n",
            "\n",
            "To excel in Module 1, which focuses on Docker and Terraform, consider the following strategies:\n",
            "\n",
            "1. **Follow Best Practices for Docker**:\n",
            "   - Store your code within your default Linux distribution for optimal file system performance, especially if you’re using WSL2 on Windows. This setup can improve the overall efficiency of Docker.\n",
            "\n",
            "2. **Ensure Proper Installation**:\n",
            "   - Double-check that all necessary dependencies are installed correctly. For example, if you encounter issues with Psycopg2 while executing commands, confirm that it’s installed via pip or conda.\n",
            "\n",
            "3. **Navigate Properly in Terraform**:\n",
            "   - Run `terraform init` from the correct working directory containing your Terraform configuration files. This prevents common errors such as initializing in an empty directory.\n",
            "\n",
            "4. **Manage Permissions**:\n",
            "   - When working with Google Cloud, make sure your service account has the correct permissions. For instance, if you encounter a \"permission denied\" error when creating buckets, verify that you're using the Project ID instead of the Project name.\n",
            "\n",
            "5. **Network Settings**:\n",
            "   - If you’re facing connectivity problems, especially for cloud services, ensure your VPN settings are configured to allow access. Consult your VPN provider if needed.\n",
            "\n",
            "6. **Utilize Documentation and Community**:\n",
            "   - Reference the official Docker and Terraform documentation for additional best practices and troubleshooting tips.\n",
            "\n",
            "By following these strategies, you can maximize your understanding and success in Module 1.\n",
            "\n",
            "### Follow-Up Question:\n",
            "Do you have specific areas within Module 1 that you're struggling with or would like more guidance on?\n",
            "\n"
          ]
        }
      ],
      "source": [
        "while True: # main Q&A loop (waits for user input in a loop)\n",
        "    question = input() # How do I do my best for module 1?\n",
        "    if question == 'stop':\n",
        "        break\n",
        "\n",
        "    message = {\"role\": \"user\", \"content\": question}\n",
        "    chat_messages.append(message)\n",
        "    # request-response loop - Handles the conversation with the model for each question.\n",
        "    while True: \n",
        "        response = client.responses.create(\n",
        "            model='gpt-4o-mini',\n",
        "            input=chat_messages,\n",
        "            tools=tools\n",
        "        )\n",
        "\n",
        "        has_messages = False\n",
        "        # Keep sending requests to API and processing responses until a standard text 'message' is received\n",
        "        for entry in response.output:\n",
        "            chat_messages.append(entry)\n",
        "\n",
        "            if entry.type == 'function_call':\n",
        "                print('function_call:', entry)\n",
        "                print()\n",
        "                result = do_call(entry)\n",
        "                chat_messages.append(result)\n",
        "            elif entry.type == 'message':\n",
        "                print(entry.content[0].text)\n",
        "                print()\n",
        "                has_messages = True\n",
        "\n",
        "        if has_messages:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3704058a-5a92-4b23-a9d9-6917a9dce950",
      "metadata": {
        "id": "3704058a-5a92-4b23-a9d9-6917a9dce950"
      },
      "source": [
        "We only exit the inner loop if there are no function calls. In this case, we ask the user for the next input (or \"stop\").\n",
        "\n",
        "Let's make it a bit nicer using HTML:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "e72ded91",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting markdown\n",
            "  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
            "Installing collected packages: markdown\n",
            "Successfully installed markdown-3.8.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "adc6338b-b742-431b-ac53-080d575fbb78",
      "metadata": {
        "id": "adc6338b-b742-431b-ac53-080d575fbb78"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "# first wget chat_assistant.py below\n",
        "from chat_assistant import ChatInterface\n",
        "import markdown "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "491da276-42e8-4069-bc46-57fe2314c3be",
      "metadata": {
        "id": "491da276-42e8-4069-bc46-57fe2314c3be",
        "outputId": "732ac017-79a9-4fa4-ca1b-f0d25520aaa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <details>\n",
              "            <summary>Function call: <tt>search({\"query\":\"module 1 tips\"})</tt></summary>\n",
              "            <div>\n",
              "                <b>Call</b>\n",
              "                <pre>ResponseFunctionToolCall(arguments='{\"query\":\"module 1 tips\"}', call_id='call_riyfYkBHeRwbQqAOKnAKTaAw', name='search', type='function_call', id='fc_68945c549eb4819f82d61e158198a64a08201fa2d5ece582', status='completed')</pre>\n",
              "            </div>\n",
              "            <div>\n",
              "                <b>Output</b>\n",
              "                <pre>[\n",
              "  {\n",
              "    \"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\\\"Murray Hill\\\") & (new_final.b_zone==\\\"Midwood\\\")).show()\\nKrishna Anand\",\n",
              "    \"section\": \"Module 5: pyspark\",\n",
              "    \"question\": \"Module Not Found Error in Jupyter Notebook .\",\n",
              "    \"course\": \"data-engineering-zoomcamp\",\n",
              "    \"_id\": 322\n",
              "  },\n",
              "  {\n",
              "    \"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
              "    \"section\": \"Module 4: analytics engineering with dbt\",\n",
              "    \"question\": \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
              "    \"course\": \"data-engineering-zoomcamp\",\n",
              "    \"_id\": 299\n",
              "  },\n",
              "  {\n",
              "    \"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\u201d\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\"` appropriately.\\nAdditionally, you can check for the version of \\u2018py4j\\u2019 of the spark you\\u2019re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\",\n",
              "    \"section\": \"Module 5: pyspark\",\n",
              "    \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
              "    \"course\": \"data-engineering-zoomcamp\",\n",
              "    \"_id\": 323\n",
              "  },\n",
              "  {\n",
              "    \"text\": \"Issue:\\ne\\u2026\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the \\u201c ModuleNotFoundError: No module named 'psycopg2' \\u201c error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\",\n",
              "    \"section\": \"Module 1: Docker and Terraform\",\n",
              "    \"question\": \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\",\n",
              "    \"course\": \"data-engineering-zoomcamp\",\n",
              "    \"_id\": 112\n",
              "  },\n",
              "  {\n",
              "    \"text\": \"create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \\\"TypeError: 'module' object is not callable\\\"\\nSolution:\\nconn_string = \\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\"\\nengine = create_engine(conn_string)\",\n",
              "    \"section\": \"Module 1: Docker and Terraform\",\n",
              "    \"question\": \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
              "    \"course\": \"data-engineering-zoomcamp\",\n",
              "    \"_id\": 124\n",
              "  }\n",
              "]</pre>\n",
              "            </div>\n",
              "            \n",
              "            </details>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <div><b>Assistant:</b></div>\n",
              "                <div><p>To do well in Module 1, here are some essential tips:</p>\n",
              "<ol>\n",
              "<li>\n",
              "<p><strong>Understand the Basics</strong>: Make sure you have a good grasp of Docker and Terraform concepts since Module 1 focuses on these tools.</p>\n",
              "</li>\n",
              "<li>\n",
              "<p><strong>Practice Installation and Setup</strong>: Be comfortable with installing PostgreSQL and Docker. Follow the course instructions carefully to avoid errors. Pay close attention to any module not found errors and how to resolve them, such as ensuring you install required libraries like <code>psycopg2</code>.</p>\n",
              "</li>\n",
              "<li>\n",
              "<p><strong>Hands-On Practice</strong>: Create projects or small tasks using Docker and Terraform to solidify your understanding. The more you practice, the better you will grasp the concepts.</p>\n",
              "</li>\n",
              "<li>\n",
              "<p><strong>Engage with the Community</strong>: Participate in discussions or forums related to the module. If you encounter challenges, don’t hesitate to seek help or clarify doubts.</p>\n",
              "</li>\n",
              "<li>\n",
              "<p><strong>Review FAQs and Solutions</strong>: Familiarize yourself with common issues faced by others in the module, like handling <code>ModuleNotFoundError</code> for <code>psycopg2</code>, and learn how to resolve them.</p>\n",
              "</li>\n",
              "</ol>\n",
              "<p>Would you like more specific guidance on any of these aspects, such as installation steps or project ideas?</p></div>\n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chat ended.\n"
          ]
        }
      ],
      "source": [
        "# How do I do well in module 1?\n",
        "chat_interface = ChatInterface()\n",
        "\n",
        "developer_prompt = \"\"\"\n",
        "You're a course teaching assistant.\n",
        "You're given a question from a course student and your task is to answer it.\n",
        "\n",
        "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
        "\n",
        "At the end of each response, ask the user a follow up question based on your answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "chat_messages = [\n",
        "    {\"role\": \"developer\", \"content\": developer_prompt},\n",
        "]\n",
        "\n",
        "# Chat loop\n",
        "while True:\n",
        "    question = input(\"You: \") # Was removed from repo\n",
        "    if question.strip().lower() == 'stop':\n",
        "        print(\"Chat ended.\")\n",
        "        break\n",
        "    print()\n",
        "\n",
        "    message = {\"role\": \"user\", \"content\": question}\n",
        "    chat_messages.append(message)\n",
        "\n",
        "    while True:  # inner request loop\n",
        "        response = client.responses.create(\n",
        "            model='gpt-4o-mini',\n",
        "            input=chat_messages,\n",
        "            tools=tools\n",
        "        )\n",
        "\n",
        "        has_messages = False\n",
        "\n",
        "        for entry in response.output:\n",
        "            chat_messages.append(entry)\n",
        "\n",
        "            if entry.type == \"function_call\":\n",
        "                result = do_call(entry)\n",
        "                chat_messages.append(result)\n",
        "                chat_interface.display_function_call(entry, result) # My changes\n",
        "\n",
        "            elif entry.type == \"message\":\n",
        "                chat_interface.display_response(entry) # My changes\n",
        "                has_messages = True\n",
        "\n",
        "        if has_messages:\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91b17b9a-7e17-4d00-9d22-5c0b50102428",
      "metadata": {
        "id": "91b17b9a-7e17-4d00-9d22-5c0b50102428"
      },
      "source": [
        "## Using multiple tools\n",
        "\n",
        "What if we also want to use this chat app to add new entries to the FAQ? We'll need another function for it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "bdf16fb1-0de0-47ec-9eb1-5a03274bb6a0",
      "metadata": {
        "id": "bdf16fb1-0de0-47ec-9eb1-5a03274bb6a0"
      },
      "outputs": [],
      "source": [
        "# Add a new custom made FAQ entry to search index\n",
        "def add_entry(question, answer):\n",
        "    doc = {\n",
        "        'question': question,\n",
        "        'text': answer,\n",
        "        'section': 'user added',\n",
        "        'course': 'data-engineering-zoomcamp'\n",
        "    }\n",
        "    index.append(doc)\n",
        "\n",
        "# Description dictionary for OpenAI function calling\n",
        "add_entry_description = {\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"add_entry\", # Allow the assistant to call add_entry automatically during a chat\n",
        "    \"description\": \"Add an entry to the FAQ database\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"question\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The question to be added to the FAQ database\",\n",
        "            },\n",
        "            \"answer\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"The answer to the question\",\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"question\", \"answer\"],\n",
        "        \"additionalProperties\": False\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D9rvltCiXmlb",
      "metadata": {
        "id": "D9rvltCiXmlb"
      },
      "source": [
        "We can just reuse the previous code. But we can also clean it up and make it more modular.\n",
        "\n",
        "See the result in [chat_assistant.py](https://github.com/alexeygrigorev/rag-agents-workshop/blob/main/chat_assistant.py)\n",
        "\n",
        "You can download it using wget:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fRCknxvYXyyQ",
      "metadata": {
        "id": "fRCknxvYXyyQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-08-07 07:31:32--  https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3495 (3.4K) [text/plain]\n",
            "Saving to: ‘chat_assistant.py’\n",
            "\n",
            "chat_assistant.py   100%[===================>]   3.41K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-08-07 07:31:32 (41.1 MB/s) - ‘chat_assistant.py’ saved [3495/3495]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#!wget https://raw.githubusercontent.com/alexeygrigorev/rag-agents-workshop/refs/heads/main/chat_assistant.py"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TjxMq92PX4Vs",
      "metadata": {
        "id": "TjxMq92PX4Vs"
      },
      "source": [
        "Here we define multiple classes:\n",
        "\n",
        "* Tools - manages function tools for the agent\n",
        "  * ```add_tool(function, description)```: Register a function with its description\n",
        "  * ```get_tools()```: Return list of registered tool descriptions\n",
        "  * ```function_call(tool_call_response)```: Execute a function call and return result\n",
        "* ChatInterface - handles user input and display formatting\n",
        "  * ```input()```: Get user input\n",
        "  * ```display(message)```: Print a message\n",
        "  * ```display_function_call(entry, result)```: Show function calls in HTML format\n",
        "  * ```display_response(entry)```: Display AI responses with markdown\n",
        "* ChatAssistant - main orchestrator for chat conversations.\n",
        "  * ```__init__(tools, developer_prompt, chat_interface, client)```: Initialize assistant\n",
        "  * ```gpt(chat_messages)```: Make OpenAI API calls\n",
        "  * ```run()```: Main chat loop handling user input and AI responses\n",
        "Let's use it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "j65tHXr7ZD1c",
      "metadata": {
        "id": "j65tHXr7ZD1c"
      },
      "outputs": [],
      "source": [
        "# Setting up a modular chat assistant using the chat_assistant module\n",
        "import chat_assistant\n",
        "\n",
        "tools = chat_assistant.Tools() # Creates a Tools object: the search function\n",
        "tools.add_tool(search, search_tool) # OpenAI function-calling description (search_tool)\n",
        "\n",
        "tools.get_tools() # Retrieve the list of available tools\n",
        "\n",
        "developer_prompt = \"\"\"\n",
        "You're a course teaching assistant.\n",
        "You're given a question from a course student and your task is to answer it.\n",
        "\n",
        "Use FAQ if your own knowledge is not sufficient to answer the question.\n",
        "\n",
        "At the end of each response, ask the user a follow up question based on your answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "chat_interface = chat_assistant.ChatInterface() # Creates a ChatInterface object for handling user input/output\n",
        "# Initializes a ChatAssistant object with the tools, prompt, chat interface, and OpenAI client\n",
        "chat = chat_assistant.ChatAssistant(\n",
        "    tools=tools,\n",
        "    developer_prompt=developer_prompt,\n",
        "    chat_interface=chat_interface,\n",
        "    client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "c7692aa7-354e-430e-985e-28517b1d80f1",
      "metadata": {
        "id": "c7692aa7-354e-430e-985e-28517b1d80f1",
        "outputId": "4b84df32-1cab-4c48-919d-b34d93a0caf6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <details>\n",
              "            <summary>Function call: <tt>search({\"query\":\"module 1 tips\"})</tt></summary>\n",
              "            <div>\n",
              "                <b>Call</b>\n",
              "                <pre>ResponseFunctionToolCall(arguments='{\"query\":\"module 1 tips\"}', call_id='call_icFaGyxjlDFIU1tMXU17W1No', name='search', type='function_call', id='fc_68945e88282c81a19d9b0bb20048ef21006ed381b0e255e6', status='completed')</pre>\n",
              "            </div>\n",
              "            <div>\n",
              "                <b>Output</b>\n",
              "                <pre>[\n",
              "  {\n",
              "    \"text\": \"Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\\\"Murray Hill\\\") & (new_final.b_zone==\\\"Midwood\\\")).show()\\nKrishna Anand\",\n",
              "    \"section\": \"Module 5: pyspark\",\n",
              "    \"question\": \"Module Not Found Error in Jupyter Notebook .\",\n",
              "    \"course\": \"data-engineering-zoomcamp\",\n",
              "    \"_id\": 322\n",
              "  },\n",
              "  {\n",
              "    \"text\": \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
              "    \"section\": \"Module 4: analytics engineering with dbt\",\n",
              "    \"question\": \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
              "    \"course\": \"data-engineering-zoomcamp\",\n",
              "    \"_id\": 299\n",
              "  },\n",
              "  {\n",
              "    \"text\": \"You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=\\u201d${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}\\u201d\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\\\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\\\"` appropriately.\\nAdditionally, you can check for the version of \\u2018py4j\\u2019 of the spark you\\u2019re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.\",\n",
              "    \"section\": \"Module 5: pyspark\",\n",
              "    \"question\": \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
              "    \"course\": \"data-engineering-zoomcamp\",\n",
              "    \"_id\": 323\n",
              "  },\n",
              "  {\n",
              "    \"text\": \"Issue:\\ne\\u2026\\nSolution:\\npip install psycopg2-binary\\nIf you already have it, you might need to update it:\\npip install psycopg2-binary --upgrade\\nOther methods, if the above fails:\\nif you are getting the \\u201c ModuleNotFoundError: No module named 'psycopg2' \\u201c error even after the above installation, then try updating conda using the command conda update -n base -c defaults conda. Or if you are using pip, then try updating it before installing the psycopg packages i.e\\nFirst uninstall the psycopg package\\nThen update conda or pip\\nThen install psycopg again using pip.\\nif you are still facing error with r pcycopg2 and showing pg_config not found then you will have to install postgresql. in MAC it is brew install postgresql\",\n",
              "    \"section\": \"Module 1: Docker and Terraform\",\n",
              "    \"question\": \"Postgres - ModuleNotFoundError: No module named 'psycopg2'\",\n",
              "    \"course\": \"data-engineering-zoomcamp\",\n",
              "    \"_id\": 112\n",
              "  },\n",
              "  {\n",
              "    \"text\": \"create_engine('postgresql://root:root@localhost:5432/ny_taxi')  I get the error \\\"TypeError: 'module' object is not callable\\\"\\nSolution:\\nconn_string = \\\"postgresql+psycopg://root:root@localhost:5432/ny_taxi\\\"\\nengine = create_engine(conn_string)\",\n",
              "    \"section\": \"Module 1: Docker and Terraform\",\n",
              "    \"question\": \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
              "    \"course\": \"data-engineering-zoomcamp\",\n",
              "    \"_id\": 124\n",
              "  }\n",
              "]</pre>\n",
              "            </div>\n",
              "            \n",
              "            </details>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <div><b>Assistant:</b></div>\n",
              "                <div><p>To do well in Module 1, here are some key tips you should consider:</p>\n",
              "<ol>\n",
              "<li>\n",
              "<p><strong>Understand the Basics of PostgreSQL</strong>: Familiarize yourself with SQL commands, data types, and database schemas. This foundational knowledge is crucial.</p>\n",
              "</li>\n",
              "<li>\n",
              "<p><strong>Install Required Packages</strong>: Make sure you have the required Python packages, such as <code>psycopg2-binary</code>, correctly installed. If you encounter any issues, you can try upgrading or reinstalling the package using:\n",
              "   <code>pip install psycopg2-binary --upgrade</code></p>\n",
              "</li>\n",
              "<li>\n",
              "<p><strong>Docker Familiarity</strong>: Since the module involves Docker, ensure that you understand how to create and manage Docker containers. You might want to experiment with different commands and configurations within Docker.</p>\n",
              "</li>\n",
              "<li>\n",
              "<p><strong>Practice Coding</strong>: Implement small projects or examples that help solidify your knowledge of the subject matter. The more you practice, the more comfortable you will be.</p>\n",
              "</li>\n",
              "<li>\n",
              "<p><strong>Utilize Office Hours and Discussion Boards</strong>: Don’t hesitate to ask questions. Engaging with instructors and fellow students can provide new insights and help clarify concepts.</p>\n",
              "</li>\n",
              "<li>\n",
              "<p><strong>Review Course Materials Regularly</strong>: Go over the modules, tutorials, and resources provided in your course to reinforce your understanding of the content.</p>\n",
              "</li>\n",
              "</ol>\n",
              "<p>If you encounter specific issues, such as errors during installations, referring to the documentation or community forums can provide solutions.</p>\n",
              "<p>Would you like advice on a specific topic within Module 1?</p></div>\n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <details>\n",
              "            <summary>Function call: <tt>add_entry({\"question\":\"How do I do well for module 1?\",\"a...)</tt></summary>\n",
              "            <div>\n",
              "                <b>Call</b>\n",
              "                <pre>ResponseFunctionToolCall(arguments='{\"question\":\"How do I do well for module 1?\",\"answer\":\"1. Understand the Basics of PostgreSQL: Familiarize yourself with SQL commands, data types, and database schemas. 2. Install Required Packages: Ensure you have required Python packages like psycopg2-binary installed. If issues arise, upgrade with `pip install psycopg2-binary --upgrade`. 3. Docker Familiarity: Understand how to create/manage Docker containers. Experiment with commands and configurations. 4. Practice Coding: Implement small projects/examples to solidify knowledge. 5. Utilize Office Hours and Discussion Boards: Engage with instructors/fellow students for insights and clarifications. 6. Review Course Materials Regularly: Go over modules and resources to reinforce understanding.\"}', call_id='call_JXsNZzSmERVCpfNJdAbuBFgM', name='add_entry', type='function_call', id='fc_68945e915b4c81a1abb50287b8ac3004006ed381b0e255e6', status='completed')</pre>\n",
              "            </div>\n",
              "            <div>\n",
              "                <b>Output</b>\n",
              "                <pre>null</pre>\n",
              "            </div>\n",
              "            \n",
              "            </details>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <div><b>Assistant:</b></div>\n",
              "                <div><p>I've added your question and answer to the FAQ. If you have any more topics or questions you'd like to address, feel free to let me know! </p>\n",
              "<p>Is there anything else you need help with regarding Module 1 or any other topic?</p></div>\n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chat ended.\n"
          ]
        }
      ],
      "source": [
        "# And run it:\n",
        "chat.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "4d694391-3be0-4623-aa53-0223ea2369a2",
      "metadata": {
        "id": "4d694391-3be0-4623-aa53-0223ea2369a2"
      },
      "outputs": [],
      "source": [
        "# Add the new tool to the custom function to add new FAQ entries to the search index\n",
        "tools.add_tool(add_entry, add_entry_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "d1bcbd65-8afe-482a-af8f-0f17cbce6acc",
      "metadata": {
        "id": "d1bcbd65-8afe-482a-af8f-0f17cbce6acc",
        "outputId": "de92e8e2-8fef-4209-c178-29613d612670"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'type': 'function',\n",
              "  'name': 'search',\n",
              "  'description': 'Search the FAQ database',\n",
              "  'parameters': {'type': 'object',\n",
              "   'properties': {'query': {'type': 'string',\n",
              "     'description': 'Search query text to look up in the course FAQ.'}},\n",
              "   'required': ['query'],\n",
              "   'additionalProperties': False}},\n",
              " {'type': 'function',\n",
              "  'name': 'add_entry',\n",
              "  'description': 'Add an entry to the FAQ database',\n",
              "  'parameters': {'type': 'object',\n",
              "   'properties': {'question': {'type': 'string',\n",
              "     'description': 'The question to be added to the FAQ database'},\n",
              "    'answer': {'type': 'string', 'description': 'The answer to the question'}},\n",
              "   'required': ['question', 'answer'],\n",
              "   'additionalProperties': False}}]"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Displays all tools (custom functions) registered with the assistant's toolset\n",
        "tools.get_tools()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ljN7kqmdZOKf",
      "metadata": {
        "id": "ljN7kqmdZOKf"
      },
      "source": [
        "And talk with the assistant:\n",
        "\n",
        "* How do I do well for module 1?\n",
        "* Add this back to FAQ\n",
        "\n",
        "And check that it's in the index:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "10114aa6-e3e7-4f2d-8669-10fde7516921",
      "metadata": {
        "id": "10114aa6-e3e7-4f2d-8669-10fde7516921",
        "outputId": "7554ecda-2081-4228-9dca-8c38af09366e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'Problem description\\nInfrastructure created in AWS with CD-Deploy Action needs to be destroyed\\nSolution description\\nFrom local:\\nterraform init -backend-config=\"key=mlops-zoomcamp-prod.tfstate\" --reconfigure\\nterraform destroy --var-file vars/prod.tfvars\\nAdded by Erick Calderin',\n",
              " 'section': 'Module 6: Best practices',\n",
              " 'question': 'How to destroy infrastructure created via GitHub Actions',\n",
              " 'course': 'mlops-zoomcamp'}"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index.docs[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "a7a9b616-7658-4a93-93cf-19818feac581",
      "metadata": {
        "id": "a7a9b616-7658-4a93-93cf-19818feac581",
        "outputId": "ec7aa364-f2d4-4f46-8afa-269fba61b82c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'text': 'Even after installing pyspark correctly on linux machine (VM ) as per course instructions, faced a module not found error in jupyter notebook .\\nThe solution which worked for me(use following in jupyter notebook) :\\n!pip install findspark\\nimport findspark\\nfindspark.init()\\nThereafter , import pyspark and create spark contex<<t as usual\\nNone of the solutions above worked for me till I ran !pip3 install pyspark instead !pip install pyspark.\\nFilter based on conditions based on multiple columns\\nfrom pyspark.sql.functions import col\\nnew_final.filter((new_final.a_zone==\"Murray Hill\") & (new_final.b_zone==\"Midwood\")).show()\\nKrishna Anand',\n",
              "  'section': 'Module 5: pyspark',\n",
              "  'question': 'Module Not Found Error in Jupyter Notebook .',\n",
              "  'course': 'data-engineering-zoomcamp',\n",
              "  '_id': 322},\n",
              " {'text': 'You need to look for the Py4J file and note the version of the filename. Once you know the version, you can update the export command accordingly, this is how you check yours:\\n` ls ${SPARK_HOME}/python/lib/ ` and then you add it in the export command, mine was:\\nexport PYTHONPATH=”${SPARK_HOME}/python/lib/Py4J-0.10.9.5-src.zip:${PYTHONPATH}”\\nMake sure that the version under `${SPARK_HOME}/python/lib/` matches the filename of py4j or you will encounter `ModuleNotFoundError: No module named \\'py4j\\'` while executing `import pyspark`.\\nFor instance, if the file under `${SPARK_HOME}/python/lib/` was `py4j-0.10.9.3-src.zip`.\\nThen the export PYTHONPATH statement above should be changed to `export PYTHONPATH=\"${SPARK_HOME}/python/lib/py4j-0.10.9.3-src.zip:$PYTHONPATH\"` appropriately.\\nAdditionally, you can check for the version of ‘py4j’ of the spark you’re using from here and update as mentioned above.\\n~ Abhijit Chakraborty: Sometimes, even with adding the correct version of py4j might not solve the problem. Simply run pip install py4j and problem should be resolved.',\n",
              "  'section': 'Module 5: pyspark',\n",
              "  'question': \"Py4JJavaError - ModuleNotFoundError: No module named 'py4j'` while executing `import pyspark`\",\n",
              "  'course': 'data-engineering-zoomcamp',\n",
              "  '_id': 323},\n",
              " {'text': \"Following dbt with BigQuery on Docker readme.md, after `docker-compose build` and `docker-compose run dbt-bq-dtc init`, encountered error `ModuleNotFoundError: No module named 'pytz'`\\nSolution:\\nAdd `RUN python -m pip install --no-cache pytz` in the Dockerfile under `FROM --platform=$build_for python:3.9.9-slim-bullseye as base`\",\n",
              "  'section': 'Module 4: analytics engineering with dbt',\n",
              "  'question': \"DBT - Error: No module named 'pytz' while setting up dbt with docker\",\n",
              "  'course': 'data-engineering-zoomcamp',\n",
              "  '_id': 299},\n",
              " {'text': 'create_engine(\\'postgresql://root:root@localhost:5432/ny_taxi\\')  I get the error \"TypeError: \\'module\\' object is not callable\"\\nSolution:\\nconn_string = \"postgresql+psycopg://root:root@localhost:5432/ny_taxi\"\\nengine = create_engine(conn_string)',\n",
              "  'section': 'Module 1: Docker and Terraform',\n",
              "  'question': \"Python - SQLALchemy - TypeError 'module' object is not callable\",\n",
              "  'course': 'data-engineering-zoomcamp',\n",
              "  '_id': 124},\n",
              " {'text': \"Error raised during the jupyter notebook’s cell execution:\\nengine = create_engine('postgresql://root:root@localhost:5432/ny_taxi').\\nSolution: Need to install Python module “psycopg2”. Can be installed by Conda or pip.\",\n",
              "  'section': 'Module 1: Docker and Terraform',\n",
              "  'question': \"Python - SQLAlchemy - ModuleNotFoundError: No module named 'psycopg2'.\",\n",
              "  'course': 'data-engineering-zoomcamp',\n",
              "  '_id': 125}]"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search(\"how do I do well for module 1?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69daf8eb",
      "metadata": {},
      "source": [
        "**Summary of the sequence**\n",
        "1. You call: search(\"how do I do well for module 1?\")\n",
        "2. search() calls: index.search(...) (from minsearch)\n",
        "3. index.search() does the actual search and ranking.\n",
        "4. Results (top 5 relevant FAQ entries) are returned to you."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30bfe2f8-c991-4af2-9a1b-2ab318763742",
      "metadata": {
        "id": "30bfe2f8-c991-4af2-9a1b-2ab318763742"
      },
      "source": [
        "## Part 4: Using PydanticAI (Frameworks)\n",
        "### Installing and using PydanticAI\n",
        "\n",
        "There are frameworks that make it easier for us to create agents\n",
        "\n",
        "One of them is [PydanticAI](https://ai.pydantic.dev/agents/):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "K8kH0LIUZ0lh",
      "metadata": {
        "id": "K8kH0LIUZ0lh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydantic-ai\n",
            "  Downloading pydantic_ai-0.6.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pydantic-ai-slim==0.6.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading pydantic_ai_slim-0.6.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting eval-type-backport>=0.2.0 (from pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: exceptiongroup in /home/codespace/miniconda3/lib/python3.10/site-packages (from pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (1.3.0)\n",
            "Collecting griffe>=1.3.2 (from pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading griffe-1.10.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: httpx>=0.27 in /home/codespace/miniconda3/lib/python3.10/site-packages (from pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (0.28.1)\n",
            "Collecting opentelemetry-api>=1.28.0 (from pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pydantic-graph==0.6.0 (from pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading pydantic_graph-0.6.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: pydantic>=2.10 in /home/codespace/miniconda3/lib/python3.10/site-packages (from pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (2.10.3)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting pydantic-evals==0.6.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading pydantic_evals-0.6.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting boto3>=1.37.24 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading boto3-1.40.4-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting mcp>=1.10.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading mcp-1.12.3-py3-none-any.whl.metadata (60 kB)\n",
            "Collecting huggingface-hub>=0.33.5 (from huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading huggingface_hub-0.34.3-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting ag-ui-protocol>=0.1.8 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading ag_ui_protocol-0.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting starlette>=0.45.3 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading starlette-0.47.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting argcomplete>=3.5.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading argcomplete-3.6.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: prompt-toolkit>=3 in /home/codespace/miniconda3/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (3.0.51)\n",
            "Requirement already satisfied: rich>=13 in /home/codespace/miniconda3/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (13.9.4)\n",
            "Collecting google-genai>=1.28.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading google_genai-1.29.0-py3-none-any.whl.metadata (43 kB)\n",
            "Collecting mistralai>=1.9.2 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading mistralai-1.9.3-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting tenacity>=8.2.3 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting openai>=1.92.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading openai-1.99.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting groq>=0.19.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading groq-0.31.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting cohere>=5.16.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading cohere-5.16.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting google-auth>=2.36.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /home/codespace/miniconda3/lib/python3.10/site-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (2.32.4)\n",
            "Collecting anthropic>=0.61.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading anthropic-0.61.0-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: anyio>=0 in /home/codespace/miniconda3/lib/python3.10/site-packages (from pydantic-evals==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (4.9.0)\n",
            "Collecting logfire-api>=1.2.0 (from pydantic-evals==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading logfire_api-4.2.0-py3-none-any.whl.metadata (971 bytes)\n",
            "Requirement already satisfied: pyyaml>=6.0.2 in /home/codespace/miniconda3/lib/python3.10/site-packages (from pydantic-evals==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (6.0.2)\n",
            "Collecting pydantic>=2.10 (from pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/codespace/miniconda3/lib/python3.10/site-packages (from anthropic>=0.61.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /home/codespace/miniconda3/lib/python3.10/site-packages (from anthropic>=0.61.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /home/codespace/miniconda3/lib/python3.10/site-packages (from anthropic>=0.61.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /home/codespace/miniconda3/lib/python3.10/site-packages (from anthropic>=0.61.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (4.12.2)\n",
            "Collecting botocore<1.41.0,>=1.40.4 (from boto3>=1.37.24->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading botocore-1.40.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.37.24->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3>=1.37.24->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere>=5.16.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading fastavro-1.12.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere>=5.16.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /home/codespace/miniconda3/lib/python3.10/site-packages (from cohere>=5.16.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (2.27.1)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /home/codespace/miniconda3/lib/python3.10/site-packages (from cohere>=5.16.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (0.21.2)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere>=5.16.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading types_requests-2.32.4.20250611-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting websockets<15.1.0,>=13.0.0 (from google-genai>=1.28.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting colorama>=0.4 (from griffe>=1.3.2->pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: certifi in /home/codespace/miniconda3/lib/python3.10/site-packages (from httpx>=0.27->pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /home/codespace/miniconda3/lib/python3.10/site-packages (from httpx>=0.27->pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (1.0.9)\n",
            "Requirement already satisfied: idna in /home/codespace/miniconda3/lib/python3.10/site-packages (from httpx>=0.27->pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (3.7)\n",
            "Requirement already satisfied: h11>=0.16 in /home/codespace/miniconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27->pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /home/codespace/miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/codespace/miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (2025.5.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/codespace/miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (24.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/codespace/miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/codespace/miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.33.5->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (1.1.5)\n",
            "Collecting aiohttp (from huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading aiohttp-3.12.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /home/codespace/miniconda3/lib/python3.10/site-packages (from mcp>=1.10.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (4.24.0)\n",
            "Collecting pydantic-settings>=2.5.2 (from mcp>=1.10.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from mcp>=1.10.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting sse-starlette>=1.6.1 (from mcp>=1.10.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting uvicorn>=0.23.1 (from mcp>=1.10.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/miniconda3/lib/python3.10/site-packages (from mistralai>=1.9.2->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (2.9.0.post0)\n",
            "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.28.0->pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: wcwidth in /home/codespace/miniconda3/lib/python3.10/site-packages (from prompt-toolkit>=3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/codespace/miniconda3/lib/python3.10/site-packages (from pydantic>=2.10->pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (0.6.0)\n",
            "Collecting pydantic-core<3.0.0,>=2.18.2 (from cohere>=5.16.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/miniconda3/lib/python3.10/site-packages (from requests>=2.32.2->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/miniconda3/lib/python3.10/site-packages (from requests>=2.32.2->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (2.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/codespace/miniconda3/lib/python3.10/site-packages (from rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/miniconda3/lib/python3.10/site-packages (from rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (2.19.1)\n",
            "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.28.0->pydantic-ai-slim==0.6.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /home/codespace/miniconda3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp>=1.10.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/miniconda3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp>=1.10.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/miniconda3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp>=1.10.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/miniconda3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp>=1.10.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (0.25.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/codespace/miniconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (0.1.0)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5.2->mcp>=1.10.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: six>=1.5 in /home/codespace/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->mistralai>=1.9.2->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai) (1.17.0)\n",
            "Collecting click>=7.0 (from uvicorn>=0.23.1->mcp>=1.10.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->huggingface-hub[inference]>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,google,groq,huggingface,mcp,mistral,openai,retries,vertexai]==0.6.0->pydantic-ai)\n",
            "  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "Downloading pydantic_ai-0.6.0-py3-none-any.whl (10 kB)\n",
            "Downloading pydantic_ai_slim-0.6.0-py3-none-any.whl (254 kB)\n",
            "Downloading pydantic_evals-0.6.0-py3-none-any.whl (52 kB)\n",
            "Downloading pydantic_graph-0.6.0-py3-none-any.whl (27 kB)\n",
            "Downloading ag_ui_protocol-0.1.8-py3-none-any.whl (7.1 kB)\n",
            "Downloading anthropic-0.61.0-py3-none-any.whl (294 kB)\n",
            "Downloading argcomplete-3.6.2-py3-none-any.whl (43 kB)\n",
            "Downloading boto3-1.40.4-py3-none-any.whl (140 kB)\n",
            "Downloading cohere-5.16.2-py3-none-any.whl (294 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
            "Downloading google_genai-1.29.0-py3-none-any.whl (222 kB)\n",
            "Downloading griffe-1.10.0-py3-none-any.whl (137 kB)\n",
            "Downloading groq-0.31.0-py3-none-any.whl (131 kB)\n",
            "Downloading huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mcp-1.12.3-py3-none-any.whl (158 kB)\n",
            "Downloading mistralai-1.9.3-py3-none-any.whl (426 kB)\n",
            "Downloading openai-1.99.1-py3-none-any.whl (767 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.8/767.8 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n",
            "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
            "Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.47.2-py3-none-any.whl (72 kB)\n",
            "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
            "Downloading botocore-1.40.4-py3-none-any.whl (14.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading fastavro-1.12.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading logfire_api-4.2.0-py3-none-any.whl (87 kB)\n",
            "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
            "Downloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
            "Downloading types_requests-2.32.4.20250611-py3-none-any.whl (20 kB)\n",
            "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
            "Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
            "Downloading aiohttp-3.12.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
            "Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
            "Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
            "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: zipp, websockets, typing-inspection, types-requests, tenacity, python-multipart, python-dotenv, pydantic-core, pyasn1, propcache, multidict, logfire-api, jmespath, httpx-sse, frozenlist, fastavro, eval-type-backport, colorama, click, cachetools, async-timeout, argcomplete, aiohappyeyeballs, yarl, uvicorn, rsa, pydantic, pyasn1-modules, importlib-metadata, huggingface-hub, griffe, botocore, aiosignal, starlette, sse-starlette, s3transfer, pydantic-settings, opentelemetry-api, google-auth, aiohttp, ag-ui-protocol, pydantic-graph, openai, mistralai, mcp, groq, google-genai, cohere, boto3, anthropic, pydantic-ai-slim, pydantic-evals, pydantic-ai\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.1\n",
            "    Uninstalling pydantic_core-2.27.1:\n",
            "      Successfully uninstalled pydantic_core-2.27.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.3\n",
            "    Uninstalling pydantic-2.10.3:\n",
            "      Successfully uninstalled pydantic-2.10.3\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.33.1\n",
            "    Uninstalling huggingface-hub-0.33.1:\n",
            "      Successfully uninstalled huggingface-hub-0.33.1\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.86.0\n",
            "    Uninstalling openai-1.86.0:\n",
            "      Successfully uninstalled openai-1.86.0\n",
            "Successfully installed ag-ui-protocol-0.1.8 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 anthropic-0.61.0 argcomplete-3.6.2 async-timeout-5.0.1 boto3-1.40.4 botocore-1.40.4 cachetools-5.5.2 click-8.2.1 cohere-5.16.2 colorama-0.4.6 eval-type-backport-0.2.2 fastavro-1.12.0 frozenlist-1.7.0 google-auth-2.40.3 google-genai-1.29.0 griffe-1.10.0 groq-0.31.0 httpx-sse-0.4.0 huggingface-hub-0.34.3 importlib-metadata-8.7.0 jmespath-1.0.1 logfire-api-4.2.0 mcp-1.12.3 mistralai-1.9.3 multidict-6.6.3 openai-1.99.1 opentelemetry-api-1.36.0 propcache-0.3.2 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.7 pydantic-ai-0.6.0 pydantic-ai-slim-0.6.0 pydantic-core-2.33.2 pydantic-evals-0.6.0 pydantic-graph-0.6.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 python-multipart-0.0.20 rsa-4.9.1 s3transfer-0.13.1 sse-starlette-3.0.2 starlette-0.47.2 tenacity-9.1.2 types-requests-2.32.4.20250611 typing-inspection-0.4.1 uvicorn-0.35.0 websockets-15.0.1 yarl-1.20.1 zipp-3.23.0\n"
          ]
        }
      ],
      "source": [
        "#!pip install pydantic-ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "c507981e-c3f4-4a0a-bc11-24cef6b757e3",
      "metadata": {
        "id": "c507981e-c3f4-4a0a-bc11-24cef6b757e3"
      },
      "outputs": [],
      "source": [
        "from pydantic_ai import Agent, RunContext\n",
        "from typing import Dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "fb375ee6-e3cc-4702-9189-3e1588eb043e",
      "metadata": {
        "id": "fb375ee6-e3cc-4702-9189-3e1588eb043e"
      },
      "outputs": [],
      "source": [
        "# Create an agent:\n",
        "chat_agent = Agent( # PydanticAI class to build an agentic application\n",
        "    'openai:gpt-4o-mini',\n",
        "    system_prompt=developer_prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "07f5b957-3dea-4d30-8110-965a69a4309e",
      "metadata": {
        "id": "07f5b957-3dea-4d30-8110-965a69a4309e"
      },
      "outputs": [],
      "source": [
        "# Lets the agent call search_tool automatically when it needs to look up information:\n",
        "@chat_agent.tool # Registers search_tool as a tool the agent can use\n",
        "# PydanticAI RunContext object provides the tool function access to the current state and metadata of the agent's run\n",
        "def search_tool(ctx: RunContext, query: str) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Search the FAQ for relevant entries matching the query.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    query : str\n",
        "        The search query string provided by the user.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of search results (up to 5), each containing relevance information\n",
        "        and associated output IDs.\n",
        "    \"\"\"\n",
        "    print(f\"search('{query}')\")\n",
        "    return search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "c00faeb7-d926-486a-bb1f-312b9c6265ee",
      "metadata": {
        "id": "c00faeb7-d926-486a-bb1f-312b9c6265ee"
      },
      "outputs": [],
      "source": [
        "# Add new question-answer pairs to the FAQ database during a conversation\n",
        "@chat_agent.tool\n",
        "def add_entry_tool(ctx: RunContext, question: str, answer: str) -> None:\n",
        "    \"\"\"\n",
        "    Add a new question-answer entry to FAQ.\n",
        "\n",
        "    This function creates a document with the given question and answer,\n",
        "    tagging it as user-added content.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    question : str\n",
        "        The question text to be added to the index.\n",
        "\n",
        "    answer : str\n",
        "        The answer or explanation corresponding to the question.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    return add_entry(question, answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "83191e3b-98b8-47bd-b7cf-038c311a268e",
      "metadata": {
        "id": "83191e3b-98b8-47bd-b7cf-038c311a268e",
        "outputId": "59a175a0-27b0-4324-d09b-d003e5d737e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "search('join course late enrollment')\n"
          ]
        }
      ],
      "source": [
        "# It reads the functions' docstrings to automatically create function definition, so we don't need to worry about it:\n",
        "user_prompt = \"I just discovered the course. Can I join now?\"\n",
        "# await keyword means this must be run in an async context (run code without blocking the program while waiting for requests or operations)\n",
        "agent_run = await chat_agent.run(user_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "271e431c-71b2-425e-888b-ddd51806afb6",
      "metadata": {
        "id": "271e431c-71b2-425e-888b-ddd51806afb6",
        "outputId": "8970d24b-b6a4-4469-de10-361bcb39536d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, you can still join the course even after the start date! Even if you don't officially register, you're eligible to submit homework. However, be mindful that there will be deadlines for turning in the final projects, so try not to leave everything until the last minute.\\n\\nWould you like to know more about the course content or any specific requirements?\""
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_run.output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NEvzBQqxa3he",
      "metadata": {
        "id": "NEvzBQqxa3he"
      },
      "source": [
        "If want to learn more about implementing chat applications with Pydantic AI:\n",
        "\n",
        "* https://ai.pydantic.dev/message-history/\n",
        "* https://ai.pydantic.dev/examples/chat-app/\n",
        "\n",
        "# Wrap up\n",
        "In this workshop, we took our RAG application and made it agentic, by first tweaking the prompts, and then using the \"function calling\" functionality from OpenAI.\n",
        "\n",
        "At the end, we put all the logic into the chat_assistant.py  script, and also explored PydanticAI to make it simpler.\n",
        "\n",
        "What's next:\n",
        "\n",
        "* MCP\n",
        "* Agent deployment\n",
        "* Agent monitoring"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
