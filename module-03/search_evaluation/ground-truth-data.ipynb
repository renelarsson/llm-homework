{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79dcb641",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Evaluating retrieval results requires a ground truth or \"gold standard\" dataset.  \n",
    "This dataset consists of many queries, and for each query, we know which documents in our knowledge base are relevant.  \n",
    "In practice, a query may have multiple relevant documents, but for simplicity, we will generate a dataset where each query is linked to one relevant FAQ record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ba3282a-6099-44b3-81c6-ba4b73d80e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1ec7f",
   "metadata": {},
   "source": [
    "## Generating Unique IDs for Each Record\n",
    "\n",
    "To evaluate retrieval, we need a way to uniquely identify each FAQ record.  \n",
    "We generate an ID for each document by hashing a combination of the course, question, and the first 10 characters of the answer text.  \n",
    "This approach helps avoid ID collisions even if questions are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9880aca9-ae97-42f5-9aa5-37bb46448841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def generate_document_id(doc):\n",
    "    # combined = f\"{doc['course']}-{doc['question']}\"\n",
    "    combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n",
    "    hash_object = hashlib.md5(combined.encode())\n",
    "    hash_hex = hash_object.hexdigest()\n",
    "    document_id = hash_hex[:8]\n",
    "    return document_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66719b38-04f3-41a8-bdd8-f33f04fe9367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign IDs to each document using the function above.\n",
    "for doc in documents:\n",
    "    doc['id'] = generate_document_id(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4672632-acc2-4c1c-96b4-d30f24598aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': '0bbf41ec'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect one of the processed documents to verify the structure and the assigned ID.\n",
    "documents[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc5f536",
   "metadata": {},
   "source": [
    "## Collision Checking\n",
    "\n",
    "We import the necessary library to help us check for ID collisions (i.e., different documents with the same ID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f08db-2302-4c50-926c-511037b46c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group documents by their generated IDs to check for any collisions.\n",
    "from collections import defaultdict\n",
    "\n",
    "hashes = defaultdict(list)\n",
    "\n",
    "for doc in documents:\n",
    "    doc_id = doc['id']\n",
    "    hashes[doc_id].append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c69c01-e952-4818-a307-94ea224ca423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(947, 948)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare number of unique IDs to number of documents. If they are not equal, there are collisions.\n",
    "len(hashes), len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e495f9-fdac-436f-88e9-44ae68844ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "593f7569 2\n"
     ]
    }
   ],
   "source": [
    "# Display any IDs that are shared by more than one document, indicating a collision.\n",
    "for k, values in hashes.items():\n",
    "    if len(values) > 1:\n",
    "        print(k, len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bed2ec-9b14-4e7c-9db4-87900b30a674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"They both do the same, it's just less typing from the script.\\nAsked by Andrew Katoch, Added by Edidiong Esu\",\n",
       "  'section': '6. Decision Trees and Ensemble Learning',\n",
       "  'question': 'Does it matter if we let the Python file create the server or if we run gunicorn directly?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '593f7569'},\n",
       " {'text': \"They both do the same, it's just less typing from the script.\",\n",
       "  'section': '6. Decision Trees and Ensemble Learning',\n",
       "  'question': 'Does it matter if we let the Python file create the server or if we run gunicorn directly?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '593f7569'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect a specific collision to understand why it happened.\n",
    "hashes['593f7569']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a488a-67af-4f21-8538-2180dc085fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed documents (with IDs) to a JSON file for later use.\n",
    "import json\n",
    "\n",
    "with open('documents-with-ids.json', 'wt') as f_out:\n",
    "    json.dump(documents, f_out, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567515e-a923-487f-9b4d-9f4ce370e2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"text\": \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  \\u201cOffice Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon\\u2019t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
      "    \"section\": \"General course-related questions\",\n",
      "    \"question\": \"Course - When will the course start?\",\n",
      "    \"course\": \"data-engineering-zoomcamp\",\n",
      "    \"id\": \"c02e79ef\"\n",
      "  },\n",
      "  {\n",
      "    \"text\": \"GitHub - DataTalksClub data-engineering-zoomcamp#prerequisites\",\n"
     ]
    }
   ],
   "source": [
    "# Preview the saved JSON file to ensure it was written correctly.\n",
    "%head documents-with-ids.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e99f3ba",
   "metadata": {},
   "source": [
    "## Prompt Template for LLM Question Generation\n",
    "\n",
    "We define a prompt template for the LLM to generate five user-like questions for each FAQ record.  \n",
    "The prompt encourages the LLM to create questions that are complete, not too short, and use as few words as possible from the original record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c062325-5608-4da6-80bf-b9ac371bc17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You emulate a student who's taking our course.\n",
    "Formulate 5 questions this student might ask based on a FAQ record. The record\n",
    "should contain the answer to the questions, and the questions should be complete and not too short.\n",
    "If possible, use as fewer words as possible from the record. \n",
    "\n",
    "The record:\n",
    "\n",
    "section: {section}\n",
    "question: {question}\n",
    "answer: {text}\n",
    "\n",
    "Provide the output in parsable JSON without using code blocks:\n",
    "\n",
    "[\"question1\", \"question2\", ..., \"question5\"]\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba636ca",
   "metadata": {},
   "source": [
    "## Initialize the OpenAI client for generating questions using the prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b8f259-eed8-4a50-b50c-2186fb154853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI client for generating questions using the prompt template.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ac1ae-b5e0-43a7-b8ad-103fd56ced54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function sends the prompt to the LLM and returns the generated questions.\n",
    "def generate_questions(doc):\n",
    "    prompt = prompt_template.format(**doc)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    json_response = response.choices[0].message.content\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2353f8-411b-4ab9-a4c2-0d158495491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store the generated questions for each document.\n",
    "from tqdm.auto import tqdm # Import a progress bar\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b2479",
   "metadata": {},
   "source": [
    "## Generate Questions for All Documents\n",
    "\n",
    "We loop through all documents, generate questions for each using the LLM, and store the results in a dictionary keyed by document ID.  \n",
    "If the process is interrupted, we can resume without regenerating questions for documents that already have results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f4b7c-7632-4475-b6df-b3c02d343287",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in tqdm(documents): \n",
    "    doc_id = doc['id']\n",
    "    if doc_id in results:\n",
    "        continue\n",
    "\n",
    "    questions = generate_questions(doc)\n",
    "    results[doc_id] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de64d355-a4c8-4633-b179-952bb38923c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously saved results to avoid regenerating questions and incurring extra costs.\n",
    "import pickle\n",
    "\n",
    "with open('results.bin', 'rb') as f_in:\n",
    "    results = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5cd8f8-ddfd-4802-908b-504722511a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"Where can I find the prerequisites for this course?\", \"How do I check the prerequisites for this course?\", \"Where are the course prerequisites listed?\", \"What are the requirements for joining this course?\", \"Where is the list of prerequisites for the course?\"]'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the generated questions for a specific document by its ID.\n",
    "results['1f6520ca']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb41849",
   "metadata": {},
   "source": [
    "## Parse LLM Results and Create Document Index\n",
    "\n",
    "We parse the JSON strings returned by the LLM into Python lists and create a lookup dictionary to quickly access document metadata by ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c928923-d3d8-4b8f-b093-887dffc8e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_resulst = {}\n",
    "\n",
    "for doc_id, json_questions in results.items():\n",
    "    parsed_resulst[doc_id] = json.loads(json_questions)\n",
    "\n",
    "doc_index = {d['id']: d for d in documents}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3640781",
   "metadata": {},
   "source": [
    "## Prepare Final Results for CSV\n",
    "\n",
    "We prepare a list of tuples containing each generated question, the course, and the relevant document ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1ad018b8-33d7-4b80-85df-de3a115aa2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []\n",
    "\n",
    "for doc_id, questions in parsed_resulst.items():\n",
    "    course = doc_index[doc_id]['course']\n",
    "    for q in questions:\n",
    "        final_results.append((q, course, doc_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b862463e",
   "metadata": {},
   "source": [
    "## Create DataFrame from Final Results and Save to CSV\n",
    "\n",
    "We create a DataFrame from the final results, with columns for question, course, and document ID. We save the final ground truth dataset as a CSV file, which can be used for evaluating retrieval systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e2b0d-53ba-4766-9f5c-aa5d85eff47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question,course,document\n",
      "When does the course begin?,data-engineering-zoomcamp,c02e79ef\n",
      "How can I get the course schedule?,data-engineering-zoomcamp,c02e79ef\n",
      "What is the link for course registration?,data-engineering-zoomcamp,c02e79ef\n",
      "How can I receive course announcements?,data-engineering-zoomcamp,c02e79ef\n",
      "Where do I join the Slack channel?,data-engineering-zoomcamp,c02e79ef\n",
      "Where can I find the prerequisites for this course?,data-engineering-zoomcamp,1f6520ca\n",
      "How do I check the prerequisites for this course?,data-engineering-zoomcamp,1f6520ca\n",
      "Where are the course prerequisites listed?,data-engineering-zoomcamp,1f6520ca\n",
      "What are the requirements for joining this course?,data-engineering-zoomcamp,1f6520ca\n"
     ]
    }
   ],
   "source": [
    "# Import pandas to save as a CSV file\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(final_results, columns=['question', 'course', 'document'])\n",
    "\n",
    "df.to_csv('ground-truth-data.csv', index=False)\n",
    "\n",
    "# Preview the generated CSV file to ensure the data is correctly formatted.\n",
    "%head ground-truth-data.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
