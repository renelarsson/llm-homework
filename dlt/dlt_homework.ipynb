{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d0374ad",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "This notebook is a starting point for turning the FAQ data into a searchable, AI-ready knowledge base using Qdrant and dlt.\n",
    "\n",
    "## Question 1: dlt Version\n",
    "\n",
    "In this homework, we will load the data from our FAQ to Qdrant\n",
    "\n",
    "Let's install dlt with Qdrant support and Qdrant client:\n",
    "```python\n",
    "pip install -q \"dlt[qdrant]\" \"qdrant-client[fastembed]\"\n",
    "```\n",
    "We load the data from our FAQ to Qdrant so we can perform efficient semantic search and retrieval over the FAQ documents using vector embeddings.\n",
    "\n",
    "Qdrant is a vector database. It stores not just the text, but also the embeddings (numerical representations) of each document. \n",
    "This allows us to:\n",
    "\n",
    "* Find similar questions or answers even if the wording is different (semantic search).\n",
    "* Build retrieval-augmented generation (RAG) systems, chatbots, or FAQ assistants that can answer user queries by finding the most relevant FAQ entries.\n",
    "* Scale to large collections of documents and perform fast, accurate searches.\n",
    "\n",
    "What's the version of dlt that you installed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8c237a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "print(dlt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419826e",
   "metadata": {},
   "source": [
    "### dlt Resourse\n",
    "For reading the FAQ data, we have this helper function (Annotate the helper function with `@dlt.resource`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6731f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requests to fetch the FAQ documents\n",
    "import requests\n",
    "\n",
    "# Annotate the helper function with @dlt.resource so dlt recognizes it as a data source\n",
    "@dlt.resource\n",
    "def zoomcamp_data():\n",
    "    # Download the FAQ documents JSON from the provided URL\n",
    "    docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "    docs_response = requests.get(docs_url)\n",
    "    documents_raw = docs_response.json()\n",
    "\n",
    "    # For each course, add the course name to each document and yield it\n",
    "    for course in documents_raw:\n",
    "        course_name = course['course']\n",
    "        for doc in course['documents']:\n",
    "            doc['course'] = course_name\n",
    "            yield doc  # Yield each document as a record for dlt (one at a time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0e6e59",
   "metadata": {},
   "source": [
    "## Question 2: dlt pipeline\n",
    "\n",
    "Now let's create a pipeline.\n",
    "\n",
    "We need to define a destination for that. Let's use the qdrant one:\n",
    "```python\n",
    "from dlt.destinations import qdrant\n",
    "\n",
    "qdrant_destination = qdrant(\n",
    "  qd_path=\"db.qdrant\", \n",
    ")\n",
    "```\n",
    "In this case, we tell dlt (and Qdrant) to create a folder with our data, and the name for it will be `db.qdrant`\n",
    "\n",
    "The destination is required so dlt knows where and how to load the data after processing it. The destination to Qdrant ensures that:\n",
    "\n",
    "* The FAQ documents and their embeddings are stored in Qdrant.\n",
    "* You can later perform vector search and retrieval on your data.\n",
    "\n",
    "How many rows were inserted into the zoomcamp_data collection? \n",
    "\n",
    "Look for \"Normalized data for the following tables:\" in the trace output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32054ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72ee2b533134025aa67a2087cf92d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b7e8f482be43f88f282a831fc567c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089a0cec97aa4c09a5a8fc29c1f8c02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e4a397bea34bb4a768a8ce8ba382df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d7d22acd9f40ebb305afa7bffb7bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9398facf34fc4a7aa1af254389581aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started at 2025-08-15 14:24:00.788837+00:00 and COMPLETED in 14.95 seconds with 4 steps.\n",
      "Step extract COMPLETED in 0.30 seconds.\n",
      "\n",
      "Load package 1755267851.2368312 is EXTRACTED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step normalize COMPLETED in 0.12 seconds.\n",
      "Normalized data for the following tables:\n",
      "- zoomcamp_data: 948 row(s)\n",
      "\n",
      "Load package 1755267851.2368312 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step load COMPLETED in 4.09 seconds.\n",
      "Pipeline zoomcamp_pipeline load step completed in 4.06 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_tagged_data\n",
      "The qdrant destination used /workspaces/llm-homework/dlt/db.qdrant location to store data\n",
      "Load package 1755267851.2368312 is LOADED and contains no failed jobs\n",
      "\n",
      "Step run COMPLETED in 14.95 seconds.\n",
      "Pipeline zoomcamp_pipeline load step completed in 4.06 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_tagged_data\n",
      "The qdrant destination used /workspaces/llm-homework/dlt/db.qdrant location to store data\n",
      "Load package 1755267851.2368312 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "# Import the Qdrant destination from dlt\n",
    "from dlt.destinations import qdrant\n",
    "\n",
    "# Create a Qdrant destination instance, specifying the folder for the database\n",
    "qdrant_destination = qdrant(\n",
    "    qd_path=\"db.qdrant\", # The folder where Qdrant will store its data files\n",
    ")\n",
    "\n",
    "# Create and run the dlt pipeline:\n",
    "# dlt will automatically generate embeddings for the documents and store them in Qdrant\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name='zoomcamp_pipeline',\n",
    "    destination=qdrant_destination,\n",
    "    dataset_name='zoomcamp_tagged_data'\n",
    ")\n",
    "\n",
    "# This is where the data is loaded into Qdrant and embeddings are generated automatically\n",
    "load_info = pipeline.run(zoomcamp_data())\n",
    "\n",
    "# Print the pipeline trace to see details about the run\n",
    "print(pipeline.last_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bab86ad",
   "metadata": {},
   "source": [
    "## Question 3. Embeddings\n",
    "\n",
    "When inserting the data, an embedding model was used. Which one?\n",
    "\n",
    "You can find this out by inspecting the meta.json file created in the target folder. During the data insertion process, a folder named db.qdrant will be created, and the meta.json file will be located inside this folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc673ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"collections\": {\n",
      "    \"zoomcamp_tagged_data\": {\n",
      "      \"vectors\": {\n",
      "        \"fast-bge-small-en\": {\n",
      "          \"size\": 384,\n",
      "          \"distance\": \"Cosine\",\n",
      "          \"hnsw_config\": null,\n",
      "          \"quantization_config\": null,\n",
      "          \"on_disk\": null,\n",
      "          \"datatype\": null,\n",
      "          \"multivector_config\": null\n",
      "        }\n",
      "      },\n",
      "      \"shard_number\": null,\n",
      "      \"sharding_method\": null,\n",
      "      \"replication_factor\": null,\n",
      "      \"write_consistency_factor\": null,\n",
      "      \"on_disk_payload\": null,\n",
      "      \"hnsw_config\": null,\n",
      "      \"wal_config\": null,\n",
      "      \"optimizers_config\": null,\n",
      "      \"init_from\": null,\n",
      "      \"quantization_config\": null,\n",
      "      \"sparse_vectors\": null,\n",
      "      \"strict_mode_config\": null\n",
      "    },\n",
      "    \"zoomcamp_tagged_data__dlt_loads\": {\n",
      "      \"vectors\": {\n",
      "        \"fast-bge-small-en\": {\n",
      "          \"size\": 384,\n",
      "          \"distance\": \"Cosine\",\n",
      "          \"hnsw_config\": null,\n",
      "          \"quantization_config\": null,\n",
      "          \"on_disk\": null,\n",
      "          \"datatype\": null,\n",
      "          \"multivector_config\": null\n",
      "        }\n",
      "      },\n",
      "      \"shard_number\": null,\n",
      "      \"sharding_method\": null,\n",
      "      \"replication_factor\": null,\n",
      "      \"write_consistency_factor\": null,\n",
      "      \"on_disk_payload\": null,\n",
      "      \"hnsw_config\": null,\n",
      "      \"wal_config\": null,\n",
      "      \"optimizers_config\": null,\n",
      "      \"init_from\": null,\n",
      "      \"quantization_config\": null,\n",
      "      \"sparse_vectors\": null,\n",
      "      \"strict_mode_config\": null\n",
      "    },\n",
      "    \"zoomcamp_tagged_data__dlt_version\": {\n",
      "      \"vectors\": {\n",
      "        \"fast-bge-small-en\": {\n",
      "          \"size\": 384,\n",
      "          \"distance\": \"Cosine\",\n",
      "          \"hnsw_config\": null,\n",
      "          \"quantization_config\": null,\n",
      "          \"on_disk\": null,\n",
      "          \"datatype\": null,\n",
      "          \"multivector_config\": null\n",
      "        }\n",
      "      },\n",
      "      \"shard_number\": null,\n",
      "      \"sharding_method\": null,\n",
      "      \"replication_factor\": null,\n",
      "      \"write_consistency_factor\": null,\n",
      "      \"on_disk_payload\": null,\n",
      "      \"hnsw_config\": null,\n",
      "      \"wal_config\": null,\n",
      "      \"optimizers_config\": null,\n",
      "      \"init_from\": null,\n",
      "      \"quantization_config\": null,\n",
      "      \"sparse_vectors\": null,\n",
      "      \"strict_mode_config\": null\n",
      "    },\n",
      "    \"zoomcamp_tagged_data__dlt_pipeline_state\": {\n",
      "      \"vectors\": {\n",
      "        \"fast-bge-small-en\": {\n",
      "          \"size\": 384,\n",
      "          \"distance\": \"Cosine\",\n",
      "          \"hnsw_config\": null,\n",
      "          \"quantization_config\": null,\n",
      "          \"on_disk\": null,\n",
      "          \"datatype\": null,\n",
      "          \"multivector_config\": null\n",
      "        }\n",
      "      },\n",
      "      \"shard_number\": null,\n",
      "      \"sharding_method\": null,\n",
      "      \"replication_factor\": null,\n",
      "      \"write_consistency_factor\": null,\n",
      "      \"on_disk_payload\": null,\n",
      "      \"hnsw_config\": null,\n",
      "      \"wal_config\": null,\n",
      "      \"optimizers_config\": null,\n",
      "      \"init_from\": null,\n",
      "      \"quantization_config\": null,\n",
      "      \"sparse_vectors\": null,\n",
      "      \"strict_mode_config\": null\n",
      "    },\n",
      "    \"zoomcamp_tagged_data_zoomcamp_data\": {\n",
      "      \"vectors\": {\n",
      "        \"fast-bge-small-en\": {\n",
      "          \"size\": 384,\n",
      "          \"distance\": \"Cosine\",\n",
      "          \"hnsw_config\": null,\n",
      "          \"quantization_config\": null,\n",
      "          \"on_disk\": null,\n",
      "          \"datatype\": null,\n",
      "          \"multivector_config\": null\n",
      "        }\n",
      "      },\n",
      "      \"shard_number\": null,\n",
      "      \"sharding_method\": null,\n",
      "      \"replication_factor\": null,\n",
      "      \"write_consistency_factor\": null,\n",
      "      \"on_disk_payload\": null,\n",
      "      \"hnsw_config\": null,\n",
      "      \"wal_config\": null,\n",
      "      \"optimizers_config\": null,\n",
      "      \"init_from\": null,\n",
      "      \"quantization_config\": null,\n",
      "      \"sparse_vectors\": null,\n",
      "      \"strict_mode_config\": null\n",
      "    }\n",
      "  },\n",
      "  \"aliases\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the embedding model used by reading db.qdrant/meta.json\n",
    "import json\n",
    "with open('db.qdrant/meta.json') as f:\n",
    "    meta = json.load(f)\n",
    "print(json.dumps(meta, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
